{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9d4d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4506,
     "status": "ok",
     "timestamp": 1764411740064,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "e9d9d4d1",
    "outputId": "7c6a0e99-adad-4fc1-a8cc-bfb1686a15cc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "google_drive_path = ''\n",
    "os.chdir(google_drive_path)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51865ec6",
   "metadata": {
    "id": "51865ec6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.interpolate import griddata\n",
    "from tqdm import trange\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from tabulate import tabulate\n",
    "from torchsummary import summary\n",
    "\n",
    "# To allow imports from parent directory\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions.Point_Sampling.point_sampler import Point_Sampler\n",
    "from File_Paths.file_paths import data_path\n",
    "from Test_Cases.Bridge_around_object.BRIDGE_Master_object import BRIDGE_Master_Object\n",
    "from Models.GINN_Models.GINN import GINN\n",
    "from Functions.Plotting_functions.smooth_FEM_plot import plot_FEM_results_smooth \n",
    "from Functions.Computations.L2_error import compute_L2_errors_2d \n",
    "from Functions.Training.Properties import Properties \n",
    "from Functions.Plotting_functions.BRIDGE_PINN_results import * \n",
    "from Functions.Plotting_functions.training_curves.BRIDGE_PINN_curves import * \n",
    "from Functions.logging.BRIDGE_PINN_logging import save_metrics_csv_2d  \n",
    "from Functions.utils import set_random_seed \n",
    "from File_Paths.file_paths import (\n",
    "    mesh_path,\n",
    "    point_cloud_path,\n",
    "    FEM_path,\n",
    "    data_path,\n",
    "    twoD_PINN_trained_model_dir, \n",
    ")\n",
    "\n",
    "# BRIDGE test case\n",
    "BRIDGE = BRIDGE_Master_Object(Normalize=True, Symmetry=False)\n",
    "BRIDGE.create_interfaces()\n",
    "material_properties = Properties(test_case=BRIDGE)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86086f7b",
   "metadata": {
    "id": "86086f7b"
   },
   "outputs": [],
   "source": [
    "\n",
    "filename = \"BRIDGE_validation_FEM_mine.xlsx\"\n",
    "\n",
    "# Build full path to the Excel file\n",
    "file_path = Path(data_path) / filename\n",
    "\n",
    "# Read Excel\n",
    "df = pd.read_excel(file_path)   \n",
    "coord_cols = [\"X Location (mm)\", \"Y Location (mm)\"]\n",
    "coords_mm = df[coord_cols].to_numpy(dtype=float)    \n",
    "result_cols = [\n",
    "    \"Equivalent (von-Mises) Stress (MPa)\",\n",
    "    \"X Displacement (mm)\",\n",
    "    \"Y Displacement (mm)\",\n",
    "]\n",
    "results = df[result_cols].to_numpy(dtype=float)     \n",
    "von_mises_FEM = results[:, 0]\n",
    "x_disp_FEM    = results[:, 1]\n",
    "y_disp_FEM    = results[:, 2]\n",
    "\n",
    "scale  = BRIDGE.domain_scaling_factor     \n",
    "center = BRIDGE.domain_center              \n",
    "\n",
    "coords_scaled = (coords_mm - center) * scale    \n",
    "x_scaled = coords_scaled[:, 0]\n",
    "y_scaled = coords_scaled[:, 1]\n",
    "\n",
    "\n",
    "plot_FEM_results_smooth(\n",
    "    coords_scaled,\n",
    "    von_mises_FEM,\n",
    "    x_disp_FEM,\n",
    "    y_disp_FEM,\n",
    "    BRIDGE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ae8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEM loading \n",
    "def load_bridge_FEM_reference():\n",
    "    \"\"\"\n",
    "    Load BRIDGE FEM reference from Excel and return a dict with scaled coords and fields.\n",
    "    \"\"\"\n",
    "    filename = \"BRIDGE_validation_FEM_mine.xlsx\"\n",
    "    file_path = Path(data_path) / filename\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(f\"[WARN] FEM file not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    coord_cols = [\"X Location (mm)\", \"Y Location (mm)\"]\n",
    "    coords_mm = df[coord_cols].to_numpy(dtype=float)  \n",
    "\n",
    "    result_cols = [\n",
    "        \"Equivalent (von-Mises) Stress (MPa)\",\n",
    "        \"X Displacement (mm)\",\n",
    "        \"Y Displacement (mm)\",\n",
    "    ]\n",
    "    results = df[result_cols].to_numpy(dtype=float)  \n",
    "\n",
    "    von_mises_FEM = results[:, 0]\n",
    "    x_disp_FEM = results[:, 1]\n",
    "    y_disp_FEM = results[:, 2]\n",
    "\n",
    "    scale = BRIDGE.domain_scaling_factor\n",
    "    center = BRIDGE.domain_center  \n",
    "\n",
    "    coords_scaled = (coords_mm - center) * scale  \n",
    "\n",
    "    fem_ref = {\n",
    "        \"coords_scaled\": coords_scaled,\n",
    "        \"x_disp\": x_disp_FEM,\n",
    "        \"y_disp\": y_disp_FEM,\n",
    "        \"sigma_vm\": von_mises_FEM,\n",
    "    }\n",
    "    print(\"Loaded FEM reference:\", file_path)\n",
    "    return fem_ref \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394806ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(torch.nn.Module):\n",
    "    def __init__(self, hparams_model, hparams_feature_expansion, mollifier_alpha):\n",
    "        super().__init__()\n",
    "        self.mollifier_alpha = mollifier_alpha\n",
    "\n",
    "        self.model = GINN(\n",
    "            BRIDGE,\n",
    "            feature_expansion=hparams_feature_expansion,\n",
    "            Model_hyperparameters=hparams_model,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def enforce_dirichlet_BC(alpha, u, coords):\n",
    "        edge_vertices = BRIDGE.edge_vertices\n",
    "\n",
    "        if isinstance(edge_vertices, torch.Tensor):\n",
    "            x_left = edge_vertices[0, 0].item()\n",
    "            x_right = edge_vertices[2, 0].item()\n",
    "        else:\n",
    "            x_left = edge_vertices[0, 0]\n",
    "            x_right = edge_vertices[2, 0]\n",
    "\n",
    "        distances_left = torch.abs(coords[:, 0] - x_left)\n",
    "        distances_right = torch.abs(coords[:, 0] - x_right)\n",
    "        multiplier_left = torch.tanh(alpha * distances_left)\n",
    "        multiplier_right = torch.tanh(alpha * distances_right)\n",
    "        multiplier = multiplier_left * multiplier_right\n",
    "        multiplier = multiplier.to(u.device)\n",
    "\n",
    "        return u * multiplier.unsqueeze(1)\n",
    "\n",
    "    def forward(self, coords):\n",
    "        u = self.model(coords)\n",
    "        return self.enforce_dirichlet_BC(self.mollifier_alpha, u, coords)\n",
    "\n",
    "\n",
    "\n",
    "class density_Model(torch.nn.Module):\n",
    "    '''used for plotting/masking etc'''\n",
    "    def __init__(self, density_alpha: float):\n",
    "        super().__init__()\n",
    "        self.density_alpha = density_alpha\n",
    "        self.dummy = nn.Parameter(torch.zeros(1), requires_grad=False)\n",
    "\n",
    "    def forward(self, coords: torch.Tensor):\n",
    "        SDF = BRIDGE.interfaces.calculate_SDF(coords)\n",
    "        rho = torch.sigmoid(-self.density_alpha * SDF)\n",
    "        return rho\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db507b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PINN_Loss(Properties):\n",
    "    def __init__(self, u_model, v_model, training_hparams):\n",
    "        super().__init__(test_case=BRIDGE)\n",
    "        self.u_model = u_model.to(self.device)\n",
    "        self.v_model = v_model.to(self.device)\n",
    "\n",
    "        self.num_neumann_pts = training_hparams[\"num_neumann_points\"]\n",
    "        self.density_exponent = training_hparams[\"density_exponent\"]\n",
    "\n",
    "    def ritz_loss(self, x, density_field):\n",
    "\n",
    "        # External Work \n",
    "        neumann_pts = self.interfaces.sample_points_on_neumann_boundary(\n",
    "            self.num_neumann_pts, \"vertical\", \"torch_tensor\"\n",
    "        ).to(self.device)\n",
    "        neumann_pts.requires_grad_(True)\n",
    "\n",
    "        R = BRIDGE.interfaces.obstacle_radius\n",
    "        arc_length = math.pi * R\n",
    "        ds = arc_length / neumann_pts.shape[0]\n",
    "\n",
    "        traction_y = self.force_vector[1] / arc_length\n",
    "        prescribed_traction = torch.zeros_like(neumann_pts)\n",
    "        prescribed_traction[:, 1] = traction_y\n",
    "\n",
    "        u_neu = self.u_model(neumann_pts).squeeze(-1)\n",
    "        v_neu = self.v_model(neumann_pts).squeeze(-1)\n",
    "        displacements_neumann = torch.stack([u_neu, v_neu], dim=1)\n",
    "\n",
    "        work = torch.sum(prescribed_traction * displacements_neumann, dim=1)\n",
    "        external_energy = torch.sum(work * ds)\n",
    "\n",
    "        # ---------- Internal Strain Energy (SIMP) ----------\n",
    "        coords = x.detach().clone().requires_grad_(True).to(self.device)\n",
    "\n",
    "        u = self.u_model(coords)\n",
    "        v = self.v_model(coords)\n",
    "\n",
    "        grad_u = torch.autograd.grad(\n",
    "            u,\n",
    "            coords,\n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "        grad_v = torch.autograd.grad(\n",
    "            v,\n",
    "            coords,\n",
    "            grad_outputs=torch.ones_like(v),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "\n",
    "        eps11 = grad_u[:, 0]\n",
    "        eps22 = grad_v[:, 1]\n",
    "        eps12 = 0.5 * (grad_u[:, 1] + grad_v[:, 0])\n",
    "        trace_epsilon = eps11 + eps22\n",
    "\n",
    "        rho = density_field.to(self.device).view(-1)\n",
    "        p = float(self.density_exponent)\n",
    "\n",
    "        lam = self.lame_lambda * torch.ones_like(eps11)\n",
    "        lam = rho.clamp(0.0, 1.0).pow(p) * lam\n",
    "\n",
    "        mu = self.lame_mu * torch.ones_like(eps11)\n",
    "        mu = rho.clamp(0.0, 1.0).pow(p) * mu\n",
    "\n",
    "        sigma_11 = 2.0 * mu * eps11 + lam * trace_epsilon\n",
    "        sigma_22 = 2.0 * mu * eps22 + lam * trace_epsilon\n",
    "        sigma_12 = 2.0 * mu * eps12\n",
    "\n",
    "        strain_energy_density = 0.5 * (\n",
    "            sigma_11 * eps11 + 2.0 * sigma_12 * eps12 + sigma_22 * eps22\n",
    "        )\n",
    "\n",
    "        internal_energy = BRIDGE.domain_volume * strain_energy_density.mean()\n",
    "\n",
    "  \n",
    "        energy = internal_energy - external_energy\n",
    "        return energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pDIAL7Z48xvV",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDIAL7Z48xvV",
    "outputId": "1f332fe0-4b68-4f4f-86da-caf370c92e1a"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FixedGeometryDataset2D(Dataset): \n",
    "    \"\"\"\n",
    "    Samples points in BRIDGE.domain and assigns density ρ(x) from the exact SDF: ρ = sigmoid(-density_alpha * SDF).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_points: int, density_alpha: float):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        sampler = Point_Sampler(\n",
    "            BRIDGE.domain,\n",
    "            BRIDGE.interfaces,\n",
    "            num_points_domain=num_points,\n",
    "            num_points_interface=0,\n",
    "        )\n",
    "        pts = next(sampler).to(self.device)  # (N,2)\n",
    "\n",
    "        SDF = BRIDGE.interfaces.calculate_SDF(pts)  # (N,1) or (N,)\n",
    "        self.density = torch.sigmoid(-density_alpha * SDF).view(-1)  # (N,)\n",
    "\n",
    "        self.points = pts  # (N,2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.points.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.points[idx], self.density[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df977a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_model = {\n",
    "    \"Model_type\": \"SIREN\",\n",
    "    \"num_hidden_layers\": 3,\n",
    "    \"num_hidden_neurons\": 180,\n",
    "    \"SIREN_hparams\": {\n",
    "        \"Model_type\": \"SIREN\",\n",
    "        \"layers\": [180, 180, 180, 180, 180],\n",
    "        \"dimensionality\": 2,\n",
    "        \"w0_initial\": 30.0,\n",
    "        \"w0\": 1.0,\n",
    "        \"skip_connection\": True,\n",
    "    },\n",
    "    \"WIRE_hparams\": {\n",
    "        \"Model_type\": \"WIRE\",\n",
    "        \"layers\": [180, 180, 180, 180],\n",
    "        \"dimensionality\": 2,\n",
    "        \"w0_initial\": 15,\n",
    "        \"w0\": 2,\n",
    "        \"sigma0\": 2,\n",
    "        \"sigma0_initial\": 2,\n",
    "        \"layer_type\": \"real_gabor\",\n",
    "        \"trainable\": False,\n",
    "        \"skip_connection\": True,\n",
    "    },\n",
    "    \"MLP_hparams\": {\n",
    "        \"Model_type\": \"MLP\",\n",
    "        \"layers\": [180, 180, 180, 180],\n",
    "        \"dimensionality\": 2,\n",
    "        \"activation_function\": \"relu\",\n",
    "        \"use_bias\": True,\n",
    "        \"use_batch_norm\": False,\n",
    "        \"use_dropout\": False,\n",
    "        \"dropout_rate\": 0.1,\n",
    "        \"skip_connection\": True,\n",
    "    },\n",
    "}\n",
    "\n",
    "hparams_feature_expansion = {\n",
    "    \"Feature Type\": \"None\",\n",
    "    \"Num Frequencies\": 3,\n",
    "    \"Max Frequency\": 100,\n",
    "}\n",
    "\n",
    "training_hparams = {\n",
    "    \"total_points\": 120_000,\n",
    "    \"batch_size\": 40_000,\n",
    "    \"num_epochs\": 5000,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"gamma\": 0.85,  \n",
    "    \"num_neumann_points\": 10_000,\n",
    "    \"mollifier_alpha\": 1.0,\n",
    "    \"density_alpha\": 1000.0,  \n",
    "    \"density_exponent\": 3,  \n",
    "    \"plot_interval\": 100,\n",
    "    \"save_path\": \"./BRIDGE_PINN_val_2\",\n",
    "    \"seed\": 43,\n",
    "}\n",
    "\n",
    "os.makedirs(training_hparams[\"save_path\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113174ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pinn_bridge_2d(fem_ref=None):\n",
    "    set_random_seed(training_hparams[\"seed\"])\n",
    "    save_dir = training_hparams[\"save_path\"]\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # models \n",
    "    u_model = PINN(hparams_model[\"SIREN_hparams\"], hparams_feature_expansion, training_hparams[\"mollifier_alpha\"]).to(device)\n",
    "    v_model = PINN(hparams_model[\"SIREN_hparams\"],hparams_feature_expansion,training_hparams[\"mollifier_alpha\"]).to(device)\n",
    "    density_model = density_Model(training_hparams[\"density_alpha\"]).to(device)\n",
    "\n",
    "    params = list(u_model.parameters()) + list(v_model.parameters())\n",
    "    optimizer = torch.optim.Adam(params=params,lr=training_hparams[\"learning_rate\"],weight_decay=training_hparams[\"weight_decay\"])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=int(training_hparams[\"num_epochs\"] / 4),gamma=training_hparams[\"gamma\"])\n",
    "\n",
    "    loss_fn = PINN_Loss(u_model, v_model, training_hparams)\n",
    "\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"loss\": [],\n",
    "        \"L2_u\": [],\n",
    "        \"L2_v\": [],\n",
    "        \"L2_s\": [],\n",
    "    }\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_model_path = os.path.join(save_dir, \"best_model_2D_fixed_new.pth\")\n",
    "\n",
    "    torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "    for epoch in trange(training_hparams[\"num_epochs\"]):\n",
    "        dataset = FixedGeometryDataset2D(\n",
    "            num_points=training_hparams[\"total_points\"],\n",
    "            density_alpha=training_hparams[\"density_alpha\"],\n",
    "        )\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=training_hparams[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for coords_batch, density_batch in dataloader:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss_ritz = loss_fn.ritz_loss(coords_batch, density_batch)\n",
    "            loss_ritz.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss_ritz.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        epoch_loss /= max(1, len(dataloader))\n",
    "\n",
    "        # L2 errors vs FEM\n",
    "        L2_u, L2_v, L2_s = compute_L2_errors_2d(\n",
    "            u_model, v_model, material_properties, fem_ref, BRIDGE\n",
    "        )\n",
    "\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"loss\"].append(epoch_loss)\n",
    "        history[\"L2_u\"].append(0.0 if L2_u is None else L2_u)\n",
    "        history[\"L2_v\"].append(0.0 if L2_v is None else L2_v)\n",
    "        history[\"L2_s\"].append(0.0 if L2_s is None else L2_s)\n",
    "\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"loss\": best_loss,\n",
    "                    \"u_model_state_dict\": u_model.state_dict(),\n",
    "                    \"v_model_state_dict\": v_model.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                },\n",
    "                best_model_path,\n",
    "            )\n",
    "\n",
    "        if (epoch % training_hparams[\"plot_interval\"]) == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch}, loss={epoch_loss:.6e}, \"\n",
    "                f\"lr={scheduler.optimizer.param_groups[0]['lr']:.3e}, \"\n",
    "                f\"best_loss={best_loss:.6e}, \"\n",
    "                f\"L2_u={history['L2_u'][-1]:.3e}, \"\n",
    "                f\"L2_v={history['L2_v'][-1]:.3e}, \"\n",
    "                f\"L2_s={history['L2_s'][-1]:.3e}\"\n",
    "            )\n",
    "\n",
    "            # NN 1×3 \n",
    "            u_img, v_img, sigma_img, rho_img = predict_uv_sigma_image_2d_binary(\n",
    "                u_model,\n",
    "                v_model,\n",
    "                density_model,\n",
    "                BRIDGE.domain,\n",
    "                BRIDGE,\n",
    "                rho_threshold_plot=0.5, \n",
    "            )\n",
    "            fname_nn_1x3 = os.path.join(save_dir, f\"uvsigma_NN_{epoch:06d}.png\")\n",
    "            save_uv_sigma_to_file(\n",
    "                u_img, v_img, sigma_img, rho_img, fname_nn_1x3, BRIDGE.domain, BRIDGE, 0.5 \n",
    "            )\n",
    "\n",
    "            # --- FEM 1×3 & 3×3 comparison ---\n",
    "            if fem_ref is not None:\n",
    "                fname_fem_1x3 = os.path.join(save_dir, f\"uvsigma_FEM_{epoch:06d}.png\")\n",
    "                save_FEM_results_smooth(fem_ref, fname_fem_1x3,BRIDGE, grid_resolution=300)\n",
    "\n",
    "                fname_3x3 = os.path.join(\n",
    "                    save_dir, f\"uvsigma_compare_{epoch:06d}.png\"\n",
    "                )\n",
    "                save_uv_sigma_comparison_grid_2d(\n",
    "                    u_model,\n",
    "                    v_model,\n",
    "                    material_properties,\n",
    "                    fem_ref,\n",
    "                    fname_3x3,\n",
    "                    BRIDGE,\n",
    "                    grid_resolution=300,\n",
    "                    rho_threshold=0.5, \n",
    "                )\n",
    "\n",
    "            # --- Training curves (linear + log) ---\n",
    "            fname_curves_lin = os.path.join(\n",
    "                save_dir, f\"training_curves_{epoch:06d}.png\"\n",
    "            )\n",
    "            fname_curves_log = os.path.join(\n",
    "                save_dir, f\"training_curves_log_{epoch:06d}.png\"\n",
    "            )\n",
    "\n",
    "            save_training_curves_2d(history, fname_curves_lin)\n",
    "            save_training_curves_log_2d(history, fname_curves_log)\n",
    "\n",
    "            #  CSV logging of metrics \n",
    "            save_metrics_csv_2d(history, save_dir)\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    print(\"Best loss:\", best_loss)\n",
    "    print(\"Best model path:\", best_model_path)\n",
    "    return best_model_path, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fem_ref = load_bridge_FEM_reference() \n",
    "best_model_path, history = train_pinn_bridge_2d(fem_ref)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
