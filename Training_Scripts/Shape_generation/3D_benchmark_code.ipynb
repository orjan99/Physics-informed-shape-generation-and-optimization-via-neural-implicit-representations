{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3486fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10056,
     "status": "ok",
     "timestamp": 1770669016882,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "bc3486fb",
    "outputId": "b6ee1d05-9442-47cf-fcc4-79207fd8941c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "google_drive_path = '' \n",
    "os.chdir(google_drive_path)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "!ls\n",
    "\n",
    "!python -m pip install trimesh\n",
    "!python -m pip install rtree\n",
    "!python -m pip install cripser==0.0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c536af",
   "metadata": {
    "executionInfo": {
     "elapsed": 2851,
     "status": "ok",
     "timestamp": 1770669019738,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "a9c536af"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import trimesh\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import cripser\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors as mcolors\n",
    "from skimage import measure\n",
    "\n",
    "from torchsummary import summary\n",
    "from scipy.interpolate import griddata\n",
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tabulate import tabulate\n",
    "\n",
    "# To allow me to import the functions from other folders from the parent directory\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90abf4",
   "metadata": {
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1770669019932,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "3b90abf4"
   },
   "outputs": [],
   "source": [
    "from Test_Cases.Jet_Engine_Bracket.JEB_Master_object import JEB_Master_object\n",
    "JEB = JEB_Master_object(Normalize=True, Symmetry=False, Expand = False, expansion_factor = 1.1)\n",
    "JEB.create_interfaces()\n",
    "\n",
    "from Functions.utils import *\n",
    "from Functions.Point_Sampling.point_sampler import *\n",
    "from Functions.Point_Sampling.BS3D import *\n",
    "from Functions.Plotting_functions.JEB_results import *\n",
    "from Functions.Plotting_functions.training_curves.JEB_curves import *\n",
    "from Functions.Computations.PH3D import *\n",
    "from Functions.Computations.eval3D import *\n",
    "from Functions.Training.enforce_Const_3D import *\n",
    "from Functions.Training.ALM import *\n",
    "from Functions.logging.JEB_logging import *\n",
    "from Functions.Training.Properties import *\n",
    "\n",
    "from Models.GINN_Models.GINN import GINN\n",
    "from File_Paths.file_paths import interfaces_path, mesh_path\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f18d19d",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770669019953,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "7f18d19d"
   },
   "outputs": [],
   "source": [
    "class SDF_GINN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 hparams_model,\n",
    "                 hparams_feature_expansion):\n",
    "\n",
    "        super().__init__()\n",
    "        self.model = GINN(JEB,\n",
    "                          feature_expansion = hparams_feature_expansion ,\n",
    "                          Model_hyperparameters = hparams_model)\n",
    "\n",
    "    def forward(self,coords):\n",
    "        SDF = self.model(coords)\n",
    "        return SDF\n",
    "\n",
    "\n",
    "class density_GINN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 hparams_model,\n",
    "                 hparams_feature_expansion,\n",
    "                 density_alpha,\n",
    "                 volume_ratio):\n",
    "\n",
    "        super().__init__()\n",
    "        self.volume_ratio = volume_ratio\n",
    "        self.density_alpha = density_alpha\n",
    "        self.model = GINN(JEB,\n",
    "                          feature_expansion = hparams_feature_expansion ,\n",
    "                          Model_hyperparameters = hparams_model)\n",
    "\n",
    "    def forward(self,coords):\n",
    "        SDF = self.model(coords)\n",
    "        v = torch.as_tensor(self.volume_ratio, dtype=SDF.dtype, device=SDF.device)\n",
    "        offset = torch.log(v / (1.0 - v))\n",
    "        rho = torch.sigmoid(self.density_alpha * SDF + offset)\n",
    "        return rho.clamp(0.0, 1.0)\n",
    "\n",
    "\n",
    "class PINN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 hparams_model,\n",
    "                 hparams_feature_expansion,\n",
    "                 mollifier_alpha):\n",
    "\n",
    "        super().__init__()\n",
    "        self.mollifier_alpha = mollifier_alpha\n",
    "\n",
    "        self.model = GINN(JEB,\n",
    "                          feature_expansion = hparams_feature_expansion ,\n",
    "                          Model_hyperparameters = hparams_model)\n",
    "\n",
    "    @staticmethod\n",
    "    def enforce_dirichlet_BC(alpha, u, coords):\n",
    "\n",
    "        device = u.device if isinstance(coords, torch.Tensor) else None\n",
    "        radius    = JEB.bolt_interface_radius\n",
    "        depth     = JEB.bolt_interface_depth\n",
    "        centroid1 = JEB.bolt1_centroid\n",
    "        centroid2 = JEB.bolt2_centroid\n",
    "        centroid3 = JEB.bolt3_centroid\n",
    "        centroid4 = JEB.bolt4_centroid\n",
    "\n",
    "        centroids = torch.tensor([\n",
    "            centroid1[0:2],\n",
    "            centroid2[0:2],\n",
    "            centroid3[0:2],\n",
    "            centroid4[0:2]\n",
    "        ], dtype=torch.float32, device=device)\n",
    "\n",
    "        x = coords[:, 0]\n",
    "        y = coords[:, 1]\n",
    "        xy_coords = torch.stack([x, y], dim=1)\n",
    "\n",
    "        multiplier_total = torch.ones(coords.shape[0], device=device)\n",
    "\n",
    "        for centroid in centroids:\n",
    "            dist = torch.norm(xy_coords - centroid, dim=1)\n",
    "\n",
    "            inside_mask = dist <= radius\n",
    "            outside_mask = dist > radius\n",
    "\n",
    "            d_inside = torch.abs(dist[inside_mask] - radius)\n",
    "            d_outside = torch.abs(radius - dist[outside_mask])\n",
    "\n",
    "            m_inside = torch.tanh(alpha * d_inside)\n",
    "            m_outside = torch.tanh(alpha * d_outside)\n",
    "\n",
    "            multiplier = torch.ones_like(dist)\n",
    "            multiplier[inside_mask] = m_inside\n",
    "            multiplier[outside_mask] = m_outside\n",
    "\n",
    "            multiplier_total *= multiplier\n",
    "\n",
    "        return u * multiplier_total.unsqueeze(1)\n",
    "\n",
    "\n",
    "    def forward(self,coords):\n",
    "        u = self.model(coords)\n",
    "        return self.enforce_dirichlet_BC(self.mollifier_alpha,u,coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa997c80",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1770669019978,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "aa997c80"
   },
   "outputs": [],
   "source": [
    "class GINN_Losses:\n",
    "    def __init__(self,\n",
    "                 GINN_model,\n",
    "                 test_case,\n",
    "                 GINN_hparams,\n",
    "                 PH,\n",
    "                 boundary_sampler,\n",
    "                 enforce_density):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.GINN_model = GINN_model.to(self.device)\n",
    "        self.GINN_hparams = GINN_hparams\n",
    "        self.boundary_sampler = boundary_sampler\n",
    "        self.test_case = test_case\n",
    "        self.enforce_density = enforce_density\n",
    "        self.dim = test_case.dim\n",
    "        self.envelope_extension_factor = self.GINN_hparams['envelope_extension_factor']\n",
    "        self.num_points_connectivity_loss = self.GINN_hparams['num_points_connectivity_loss']\n",
    "        self.num_points_interface_loss = self.GINN_hparams['num_points_interface_loss']\n",
    "        self.num_points_normals_loss = self.GINN_hparams['num_points_normals_loss']\n",
    "        self.num_points_envelope_loss = self.GINN_hparams['num_points_envelope_loss']\n",
    "        self.clip_max_value = self.GINN_hparams['clip_max_value']\n",
    "        self.clip_min_value = self.GINN_hparams['clip_min_value']\n",
    "        self.max_curv = self.GINN_hparams['max_curv']\n",
    "        self.curv_start_epoch = self.GINN_hparams['curv_start_epoch']\n",
    "        self.PH = PH\n",
    "\n",
    "    def surface_normal_loss(self):\n",
    "        normals = self.test_case.interfaces.get_all_prescribed_surface_normals(\n",
    "            num_points=self.num_points_normals_loss,\n",
    "            type='torch_tensor',\n",
    "            include_all=True\n",
    "        )\n",
    "        points = normals['points'].to(self.device)\n",
    "        neumann_points          = points[normals['neumann_idx']]\n",
    "        dirichlet_points        = points[normals['dirichlet_idx']]\n",
    "        inp = torch.vstack([neumann_points, dirichlet_points]).to(self.device)\n",
    "        inp = inp.requires_grad_(True)\n",
    "\n",
    "        target_surface_normals = torch.vstack([normals['neumann_normals'],\n",
    "                                               normals['dirichlet_normals']]).to(self.device)\n",
    "\n",
    "        SDF_values = self.GINN_model(inp).view(-1)\n",
    "        predicted_surface_normals = torch.autograd.grad(\n",
    "            inputs=inp,\n",
    "            outputs=SDF_values,\n",
    "            grad_outputs=torch.ones_like(SDF_values),\n",
    "            create_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        predicted_surface_normals = F.normalize(predicted_surface_normals, p=2, dim=1)\n",
    "        loss = F.mse_loss(predicted_surface_normals, target_surface_normals)\n",
    "        return loss\n",
    "\n",
    "    def prohibited_region_loss(self, coords):\n",
    "        inside_points, inside_mask = self.test_case.interfaces.is_inside_prohibited_region(coords)\n",
    "        SDF = self.GINN_model(coords).squeeze()\n",
    "        SDF_inside = SDF[inside_mask].view(-1)\n",
    "        violation_mask = (SDF_inside < 0)\n",
    "        SDF_violations = SDF_inside[violation_mask]\n",
    "        if SDF_violations.numel() > 0:\n",
    "            loss = torch.square(SDF_violations).sum()\n",
    "        else:\n",
    "            loss = torch.tensor(0.0, device=SDF.device, dtype=torch.float32, requires_grad=True)\n",
    "        return loss\n",
    "\n",
    "    def prescribed_thickness_loss(self, coords):\n",
    "        inside_points, inside_mask = self.test_case.interfaces.is_inside_interface_thickness(coords)\n",
    "        SDF = self.GINN_model(coords).squeeze()\n",
    "        SDF_inside = SDF[inside_mask].view(-1)\n",
    "        violation_mask = (SDF_inside > 0)\n",
    "        SDF_violations = SDF_inside[violation_mask]\n",
    "        if SDF_violations.numel() > 0:\n",
    "            prescribed_thickness_loss = torch.square(SDF_violations).sum()\n",
    "        else:\n",
    "            prescribed_thickness_loss = torch.tensor(0.0, device=SDF.device, dtype=torch.float32, requires_grad=True)\n",
    "        return prescribed_thickness_loss\n",
    "\n",
    "    def interface_loss(self):\n",
    "        coords = self.test_case.interfaces.sample_points_from_all_interfaces(\n",
    "            self.num_points_interface_loss,\n",
    "            random_seed=None,\n",
    "            output_type='torch_tensor'\n",
    "        )\n",
    "        input = coords.detach().to(self.device)\n",
    "        sdf_values = self.GINN_model(input).view(-1,1)\n",
    "        target_sdf_values = torch.zeros_like(sdf_values)\n",
    "        interface_loss = F.mse_loss(sdf_values, target_sdf_values)\n",
    "        return interface_loss\n",
    "\n",
    "    def eikonal_loss(self, coords):\n",
    "        coords.requires_grad_(True)\n",
    "        SDF = self.GINN_model(coords).squeeze()\n",
    "        SDF_grad = torch.autograd.grad(outputs=SDF, inputs=coords, grad_outputs=torch.ones_like(SDF), create_graph=True)[0]\n",
    "        SDF_grad_norm = torch.norm(SDF_grad, dim=1)\n",
    "        eikonal_loss = torch.mean((SDF_grad_norm - 1) ** 2)\n",
    "        return eikonal_loss\n",
    "\n",
    "    def design_envelope_loss(self):\n",
    "        design_envelope = self.test_case.domain\n",
    "        x_min_domain = design_envelope[0]; x_max_domain = design_envelope[1]\n",
    "        y_min_domain = design_envelope[2]; y_max_domain = design_envelope[3]\n",
    "        z_min_domain = design_envelope[4]; z_max_domain = design_envelope[5]\n",
    "\n",
    "        extension_factor = self.GINN_hparams['envelope_extension_factor']\n",
    "        x_min_extended = x_min_domain - extension_factor * (x_max_domain - x_min_domain)\n",
    "        x_max_extended = x_max_domain + extension_factor * (x_max_domain - x_min_domain)\n",
    "        y_min_extended = y_min_domain - extension_factor * (y_max_domain - y_min_domain)\n",
    "        y_max_extended = y_max_domain + extension_factor * (y_max_domain - y_min_domain)\n",
    "        z_min_extended = z_min_domain - extension_factor * (z_max_domain - z_min_domain)\n",
    "        z_max_extended = z_max_domain + extension_factor * (z_max_domain - z_min_domain)\n",
    "\n",
    "        extended_domain = np.array([x_min_extended, x_max_extended, y_min_extended, y_max_extended, z_min_extended, z_max_extended])\n",
    "\n",
    "        point_sampler = Point_Sampler(extended_domain,\n",
    "                                      num_points_domain=self.num_points_envelope_loss)\n",
    "        points = next(point_sampler).to(self.device)\n",
    "        points.requires_grad_(True)\n",
    "\n",
    "        c1 = torch.logical_and(points[:, 0] >= x_min_domain, points[:, 0] <= x_max_domain)\n",
    "        c2 = torch.logical_and(points[:, 1] >= y_min_domain, points[:, 1] <= y_max_domain)\n",
    "        c3 = torch.logical_and(points[:, 2] >= z_min_domain, points[:, 2] <= z_max_domain)\n",
    "        mask = c1 & c2 & c3\n",
    "\n",
    "        points_outside_envelope = points[~mask]\n",
    "        if points_outside_envelope.shape[0] == 0:\n",
    "            raise ValueError(\"No points sampled outside the design envelope. Increase points or extension.\")\n",
    "\n",
    "        sdf_values = self.GINN_model(points_outside_envelope).view(-1)\n",
    "        violation_mask = (sdf_values <= 0)\n",
    "        SDF_constraint_violations = sdf_values[violation_mask]\n",
    "        if SDF_constraint_violations.numel() > 0:\n",
    "            envelope_loss = torch.square(SDF_constraint_violations).sum()\n",
    "        else:\n",
    "            envelope_loss = torch.tensor(0.0, device=sdf_values.device, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        return envelope_loss\n",
    "\n",
    "\n",
    "    def smoothness_loss(self, epoch) -> torch.Tensor:\n",
    "        if epoch < self.curv_start_epoch:\n",
    "            return torch.tensor(0.0, device=device, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        surface_points, weights = self.boundary_sampler.get_surface_pts()\n",
    "        if surface_points is None or surface_points.numel() == 0:\n",
    "            print('Returning Zero Loss - No Surface Points Found')\n",
    "            return torch.tensor(0.0, device=device, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        pts = surface_points.to(device)\n",
    "        if pts.dim() != 2:\n",
    "            raise ValueError(f\"surface_points must be [B, D], got {pts.shape}\")\n",
    "        w = weights.to(device)\n",
    "        if w.dim() == 2 and w.size(-1) == 1:\n",
    "            w = w.squeeze(-1)\n",
    "        if w.dim() != 1 or w.shape[0] != pts.shape[0]:\n",
    "            raise ValueError(f\"weights must be [B] or [B,1] matching points. Got {weights.shape}\")\n",
    "\n",
    "        B, D = pts.shape\n",
    "        pts = pts.clone().detach().requires_grad_(True)\n",
    "        sdf = self.GINN_model(pts).view(-1)\n",
    "        grad_outputs = torch.ones_like(sdf)\n",
    "\n",
    "        df_dx = torch.autograd.grad(\n",
    "            outputs=sdf, inputs=pts, grad_outputs=grad_outputs,\n",
    "            create_graph=True, retain_graph=True, only_inputs=True,\n",
    "        )[0]  # [B, D]\n",
    "\n",
    "        H_rows = []\n",
    "        for d in range(D):\n",
    "            g_comp = df_dx[:, d]\n",
    "            Hg = torch.autograd.grad(\n",
    "                outputs=g_comp, inputs=pts, grad_outputs=torch.ones_like(g_comp),\n",
    "                create_graph=True, retain_graph=True, only_inputs=True,\n",
    "            )[0]\n",
    "            H_rows.append(Hg.unsqueeze(1))\n",
    "        H = torch.cat(H_rows, dim=1)  # [B, D, D]\n",
    "\n",
    "        grad_sq = (df_dx.square()).sum(dim=1)\n",
    "        F4 = torch.clamp(grad_sq.square(), min=1.0e-15)\n",
    "\n",
    "        top = torch.cat([H, df_dx.unsqueeze(2)], dim=2)\n",
    "        bottom = torch.cat([df_dx.unsqueeze(1), torch.zeros(B, 1, 1, device=device, dtype=H.dtype)], dim=2)\n",
    "        aug = torch.cat([top, bottom], dim=1)\n",
    "        det_aug = torch.det(aug)\n",
    "        gauss_curvatures = (-1.0) / F4 * det_aug\n",
    "\n",
    "        FHFT = torch.einsum('bi,bij,bj->b', df_dx, H, df_dx)\n",
    "        trH = torch.einsum('bii->b', H)\n",
    "        N = torch.clamp(grad_sq.sqrt(), min=1.0e-5)\n",
    "        mean_curvatures = -(FHFT - (N.pow(2) * trH)) / (2.0 * N.pow(3))\n",
    "\n",
    "        E_strain = (2.0 * mean_curvatures).pow(2) - 2.0 * gauss_curvatures\n",
    "        E_strain = torch.clamp(E_strain, min=self.clip_min_value, max=self.clip_max_value)\n",
    "        E_strain = E_strain * w\n",
    "        total = E_strain.sum()\n",
    "\n",
    "        zero = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
    "        loss = torch.maximum(zero, total - float(self.max_curv))\n",
    "        return loss\n",
    "\n",
    "    def connectivity_loss(self) -> torch.Tensor:\n",
    "        return self.PH.connectedness_loss()\n",
    "\n",
    "    def holes_loss(self):\n",
    "        return self.PH.holes_loss()\n",
    "\n",
    "\n",
    "    def design_envelope_loss_from_density(self,\n",
    "                                          density_model: torch.nn.Module,\n",
    "                                          iso_level: float = 0.5) -> torch.Tensor:\n",
    "\n",
    "        rho_threshold = iso_level\n",
    "\n",
    "        design_envelope = self.test_case.domain\n",
    "        x_min_domain = design_envelope[0]; x_max_domain = design_envelope[1]\n",
    "        y_min_domain = design_envelope[2]; y_max_domain = design_envelope[3]\n",
    "        z_min_domain = design_envelope[4]; z_max_domain = design_envelope[5]\n",
    "\n",
    "        extension_factor = self.envelope_extension_factor\n",
    "        x_min_extended = x_min_domain - extension_factor * (x_max_domain - x_min_domain)\n",
    "        x_max_extended = x_max_domain + extension_factor * (x_max_domain - x_min_domain)\n",
    "        y_min_extended = y_min_domain - extension_factor * (y_max_domain - y_min_domain)\n",
    "        y_max_extended = y_max_domain + extension_factor * (y_max_domain - y_min_domain)\n",
    "        z_min_extended = z_min_domain - extension_factor * (z_max_domain - z_min_domain)\n",
    "        z_max_extended = z_max_domain + extension_factor * (z_max_domain - z_min_domain)\n",
    "\n",
    "        extended_domain = np.array([x_min_extended, x_max_extended,\n",
    "                                    y_min_extended, y_max_extended,\n",
    "                                    z_min_extended, z_max_extended],\n",
    "                                   dtype=np.float32)\n",
    "\n",
    "        point_sampler = Point_Sampler(\n",
    "            extended_domain,\n",
    "            num_points_domain=self.num_points_envelope_loss,\n",
    "            num_points_interface=0\n",
    "        )\n",
    "        points = next(point_sampler).to(self.device)   # [N,3]\n",
    "\n",
    "        c1 = torch.logical_and(points[:, 0] >= x_min_domain, points[:, 0] <= x_max_domain)\n",
    "        c2 = torch.logical_and(points[:, 1] >= y_min_domain, points[:, 1] <= y_max_domain)\n",
    "        c3 = torch.logical_and(points[:, 2] >= z_min_domain, points[:, 2] <= z_max_domain)\n",
    "        mask_inside = c1 & c2 & c3\n",
    "\n",
    "        points_outside = points[~mask_inside]\n",
    "        if points_outside.shape[0] == 0:\n",
    "            return torch.tensor(0.0, device=self.device, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        rho_out = density_model(points_outside).view(-1)\n",
    "        rho_out = torch.clamp(rho_out, 0.0, 1.0)\n",
    "\n",
    "        violation_mask = (rho_out > rho_threshold)\n",
    "        rho_viol = rho_out[violation_mask]\n",
    "\n",
    "        if rho_viol.numel() > 0:\n",
    "            env_loss = torch.square(rho_viol-iso_level).sum()\n",
    "        else:\n",
    "            env_loss = torch.tensor(0.0, device=self.device, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        return env_loss\n",
    "\n",
    "\n",
    "    def connectivity_loss_from_density(self,\n",
    "                                   density_model: torch.nn.Module,\n",
    "                                   iso_level: float = 0.5) -> torch.Tensor:\n",
    "        return self.PH.connectedness_loss_from_density(density_model, iso_level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8a614",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1770669019989,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "5fe8a614"
   },
   "outputs": [],
   "source": [
    "class PINN_losses(Properties):\n",
    "    def __init__(self,\n",
    "                 u_model,\n",
    "                 v_model,\n",
    "                 w_model,\n",
    "                 GINN_model,\n",
    "                 n_opt_samples,\n",
    "                 training_hparams,\n",
    "                 enforce_density):\n",
    "        super().__init__(test_case=JEB)\n",
    "        self.u_model = u_model.to(self.device)\n",
    "        self.v_model = v_model.to(self.device)\n",
    "        self.w_model = w_model.to(self.device)\n",
    "        self.GINN_model = GINN_model.to(self.device)\n",
    "        self.n_opt_samples = n_opt_samples\n",
    "        self.enforce_density = enforce_density\n",
    "        self.dirichlet_pts = training_hparams['dirichlet_pts']\n",
    "        self.num_neumann_pts = training_hparams['num_neumann_points']\n",
    "        self.density_exponent = training_hparams['density_exponent']\n",
    "\n",
    "\n",
    "    def ritz_loss(self,x):\n",
    "\n",
    "        # External Work\n",
    "        neumann_pts = self.interfaces.sample_points_on_neumann_boundary(self.num_neumann_pts, 'vertical', 'torch_tensor').to(self.device)\n",
    "        neumann_pts.requires_grad_(True)\n",
    "\n",
    "        R = JEB.pinn_interface_radius\n",
    "        width = JEB.pinn_interface_width\n",
    "        arc_area = 2 * np.pi * R * width\n",
    "        ds = arc_area / neumann_pts.shape[0]\n",
    "\n",
    "\n",
    "        traction_z = self.force_vector[2] / arc_area\n",
    "        prescribed_traction = torch.zeros_like(neumann_pts)\n",
    "        prescribed_traction[:, 2] = traction_z\n",
    "\n",
    "        u_neu = self.u_model(neumann_pts).squeeze(-1)\n",
    "        v_neu = self.v_model(neumann_pts).squeeze(-1)\n",
    "        w_neu = self.w_model(neumann_pts).squeeze(-1)\n",
    "        displacements_neumann = torch.stack([u_neu, v_neu, w_neu], dim=1)\n",
    "\n",
    "        work_density = torch.sum(prescribed_traction * displacements_neumann, dim=1)  # shape (N,)\n",
    "        external_energy = torch.sum(work_density * ds)\n",
    "\n",
    "        #Internal Strain Energy\n",
    "        densities = self.GINN_model(x)\n",
    "        densities, _ = self.enforce_density.apply(x,densities, None, self.n_opt_samples, JEB.domain)\n",
    "\n",
    "        coords = x.detach().clone().requires_grad_(True).to(self.device)\n",
    "\n",
    "        u = self.u_model(coords)\n",
    "        v = self.v_model(coords)\n",
    "        w = self.w_model(coords)\n",
    "\n",
    "        grad_u = torch.autograd.grad(u, coords, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "        grad_v = torch.autograd.grad(v, coords, grad_outputs=torch.ones_like(v), create_graph=True, retain_graph=True)[0]\n",
    "        grad_w = torch.autograd.grad(w, coords, grad_outputs=torch.ones_like(w), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        epsilon_11 = grad_u[:, 0]  # du/dx\n",
    "        epsilon_22 = grad_v[:, 1]  # dv/dy\n",
    "        epsilon_33 = grad_w[:, 2]  # dw/dz\n",
    "\n",
    "        epsilon_12 = 0.5 * (grad_u[:, 1] + grad_v[:, 0])  # shear xy\n",
    "        epsilon_13 = 0.5 * (grad_u[:, 2] + grad_w[:, 0])  # shear xz\n",
    "        epsilon_23 = 0.5 * (grad_v[:, 2] + grad_w[:, 1])  # shear yz\n",
    "\n",
    "        trace_epsilon = epsilon_11 + epsilon_22 + epsilon_33\n",
    "\n",
    "        densities = densities.squeeze()\n",
    "        lame_lambda = self.lame_lambda * torch.ones_like(epsilon_11)\n",
    "        lame_lambda = densities.clamp(0.0, 1.0).pow(self.density_exponent)*lame_lambda\n",
    "\n",
    "        lame_mu = self.lame_mu * torch.ones_like(epsilon_11)\n",
    "        lame_mu = densities.clamp(0.0, 1.0).pow(self.density_exponent)*lame_mu\n",
    "\n",
    "        sigma_11 = 2 * lame_mu * epsilon_11 + lame_lambda * trace_epsilon\n",
    "        sigma_22 = 2 * lame_mu * epsilon_22 + lame_lambda * trace_epsilon\n",
    "        sigma_33 = 2 * lame_mu * epsilon_33 + lame_lambda * trace_epsilon\n",
    "        sigma_12 = 2 * lame_mu * epsilon_12\n",
    "        sigma_13 = 2 * lame_mu * epsilon_13\n",
    "        sigma_23 = 2 * lame_mu * epsilon_23\n",
    "\n",
    "        strain_energy_density = 0.5 * (\n",
    "            sigma_11 * epsilon_11 +\n",
    "            sigma_22 * epsilon_22 +\n",
    "            sigma_33 * epsilon_33 +\n",
    "            2 * sigma_12 * epsilon_12 +\n",
    "            2 * sigma_13 * epsilon_13 +\n",
    "            2 * sigma_23 * epsilon_23\n",
    "        )\n",
    "\n",
    "        # Approximate domain volume using volume fraction field\n",
    "        internal_energy = JEB.domain_volume * strain_energy_density.mean()\n",
    "\n",
    "        #Total Potential Energy\n",
    "        energy = internal_energy - external_energy\n",
    "\n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef9902f",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1770669020015,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "6ef9902f"
   },
   "outputs": [],
   "source": [
    "class topology_optimization(Properties):\n",
    "    def __init__(self,\n",
    "                 u_model,\n",
    "                 v_model,\n",
    "                 w_model,\n",
    "                 GINN_model,\n",
    "                 n_opt_samples,\n",
    "                 training_hparams,\n",
    "                 enforce_density):\n",
    "        super().__init__(test_case=JEB)\n",
    "        self.u_model = u_model.to(self.device)\n",
    "        self.v_model = v_model.to(self.device)\n",
    "        self.w_model = w_model.to(self.device)\n",
    "        self.GINN_model = GINN_model.to(self.device)\n",
    "        self.n_opt_samples = n_opt_samples\n",
    "        self.enforce_density = enforce_density\n",
    "        self.density_exponent = training_hparams['density_exponent']\n",
    "\n",
    "    def compute_sensitivities(self,coords):\n",
    "        self.u_model.eval(); self.v_model.eval(); self.GINN_model.eval()\n",
    "        with torch.enable_grad():\n",
    "            densities = self.GINN_model(coords).detach()\n",
    "\n",
    "            # Enforce hard density constraints\n",
    "            densities, _ = self.enforce_density.apply(coords,densities, None,self.n_opt_samples,JEB.domain)\n",
    "            densities.requires_grad_(True)\n",
    "\n",
    "            coords.requires_grad_(True)\n",
    "\n",
    "            u = self.u_model(coords)\n",
    "            v = self.v_model(coords)\n",
    "            w = self.w_model(coords)\n",
    "\n",
    "            grad_u = torch.autograd.grad(u, coords, grad_outputs=torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "            grad_v = torch.autograd.grad(v, coords, grad_outputs=torch.ones_like(v), create_graph=True, retain_graph=True)[0]\n",
    "            grad_w = torch.autograd.grad(w, coords, grad_outputs=torch.ones_like(w), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "            epsilon_11 = grad_u[:, 0]  # du/dx\n",
    "            epsilon_22 = grad_v[:, 1]  # dv/dy\n",
    "            epsilon_33 = grad_w[:, 2]  # dw/dz\n",
    "\n",
    "            epsilon_12 = 0.5 * (grad_u[:, 1] + grad_v[:, 0])  # shear xy\n",
    "            epsilon_13 = 0.5 * (grad_u[:, 2] + grad_w[:, 0])  # shear xz\n",
    "            epsilon_23 = 0.5 * (grad_v[:, 2] + grad_w[:, 1])  # shear yz\n",
    "\n",
    "            trace_epsilon = epsilon_11 + epsilon_22 + epsilon_33\n",
    "\n",
    "            densities = densities.squeeze()\n",
    "            lame_lambda = self.lame_lambda * torch.ones_like(epsilon_11)\n",
    "            lame_lambda = densities.clamp(0.0, 1.0).pow(self.density_exponent)*lame_lambda\n",
    "\n",
    "            lame_mu = self.lame_mu * torch.ones_like(epsilon_11)\n",
    "            lame_mu = densities.clamp(0.0, 1.0).pow(self.density_exponent)*lame_mu\n",
    "\n",
    "            sigma_11 = 2 * lame_mu * epsilon_11 + lame_lambda * trace_epsilon\n",
    "            sigma_22 = 2 * lame_mu * epsilon_22 + lame_lambda * trace_epsilon\n",
    "            sigma_33 = 2 * lame_mu * epsilon_33 + lame_lambda * trace_epsilon\n",
    "            sigma_12 = 2 * lame_mu * epsilon_12\n",
    "            sigma_13 = 2 * lame_mu * epsilon_13\n",
    "            sigma_23 = 2 * lame_mu * epsilon_23\n",
    "\n",
    "            strain_energy_density = 0.5 * (\n",
    "                sigma_11 * epsilon_11 +\n",
    "                sigma_22 * epsilon_22 +\n",
    "                sigma_33 * epsilon_33 +\n",
    "                2 * sigma_12 * epsilon_12 +\n",
    "                2 * sigma_13 * epsilon_13 +\n",
    "                2 * sigma_23 * epsilon_23\n",
    "            )\n",
    "\n",
    "            internal_energy = JEB.domain_volume * strain_energy_density.mean()\n",
    "\n",
    "            loss = internal_energy\n",
    "\n",
    "            (d_rho,) = torch.autograd.grad(loss,densities, retain_graph=False, create_graph=False, allow_unused=False)\n",
    "            sensitivities = -d_rho  # match TF custom-gradient sign from NTopo implementation \n",
    "\n",
    "        return densities.detach(), sensitivities.detach()\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_constant_3d_count(nx, ny, nz, rep: int, device, dtype):\n",
    "        \"\"\"Helper for sensitivity filter - following method from https://github.com/JonasZehn/ntopo/tree/main/ntopo \"\"\"\n",
    "        return torch.ones((1,1,nx,ny,nz), device=device, dtype=dtype)\n",
    "\n",
    "    def apply_sensitivity_filter_3d(self,\n",
    "                                    coords: torch.Tensor,\n",
    "                                    old_densities: torch.Tensor,\n",
    "                                    sensitivities: torch.Tensor,\n",
    "                                    n_samples: Tuple[int,int,int],\n",
    "                                    domain: np.ndarray,\n",
    "                                    radius: float) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        PyTorch analogue of ntopo.apply_sensitivity_filter_3d:\n",
    "        - adopted from https://github.com/JonasZehn/ntopo/tree/main/ntopo .\n",
    "        \"\"\"\n",
    "        gamma = 1e-3\n",
    "        nx, ny, nz = int(n_samples[0]), int(n_samples[1]), int(n_samples[2])\n",
    "        N = nx * ny * nz\n",
    "        assert coords.shape[0] == N\n",
    "\n",
    "        dx = (domain[1] - domain[0]) / nx\n",
    "        dy = (domain[3] - domain[2]) / ny\n",
    "        dz = (domain[5] - domain[4]) / nz\n",
    "\n",
    "        device = coords.device\n",
    "        dtype  = old_densities.dtype\n",
    "\n",
    "        fsize = 2*round(radius) + 1\n",
    "        rep = fsize // 2\n",
    "        radius_space = radius * dx\n",
    "\n",
    "        rng = torch.arange(-rep, rep+1, device=device, dtype=dtype)\n",
    "        IX, IY, IZ = torch.meshgrid(rng, rng, rng, indexing='ij')\n",
    "        D = torch.sqrt( (IX*dx)**2 + (IY*dy)**2 + (IZ*dz)**2 + 1e-35 )\n",
    "        K = torch.clamp(radius_space - D, min=0.0)  # [f,f,f]\n",
    "        K = K.view(1, 1, fsize, fsize, fsize)\n",
    "\n",
    "        dens = old_densities.view(nx, ny, nz).unsqueeze(0).unsqueeze(0)\n",
    "        sens = sensitivities.view(nx, ny, nz).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        num = F.conv3d(dens * sens, K, stride=1, padding=rep)\n",
    "        ones = self.pad_constant_3d_count(nx, ny, nz, rep, device, dtype)\n",
    "        sum_Hei = F.conv3d(ones, K, stride=1, padding=rep)\n",
    "\n",
    "        rho_center = torch.clamp(old_densities.view(1,1,nx,ny,nz), min=gamma)\n",
    "        div = rho_center * sum_Hei + 1e-35\n",
    "\n",
    "        grads = (num / div).view(-1, 1)  # [N,1]\n",
    "        return grads\n",
    "\n",
    "\n",
    "    def apply_sensitivity_filter(self,\n",
    "                                 coords: torch.Tensor,\n",
    "                                 old_densities: torch.Tensor,\n",
    "                                 sensitivities: torch.Tensor,\n",
    "                                 n_samples,\n",
    "                                 domain: np.ndarray,\n",
    "                                 radius: float) -> torch.Tensor:\n",
    "        return self.apply_sensitivity_filter_3d(coords, old_densities, sensitivities, n_samples, domain, radius)\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_target_densities(self,\n",
    "                                old_densities_list,\n",
    "                                sensitivities_list,\n",
    "                                sample_volume: float,\n",
    "                                target_volume: float,\n",
    "                                max_move: float,\n",
    "                                damping_parameter: float):\n",
    "        \"\"\" Compute target densities using OC update rule: derived from https://github.com/JonasZehn/ntopo/tree/main/ntopo \"\"\"\n",
    "        total = sum([odi.numel() for odi in old_densities_list])\n",
    "        dv = sample_volume / float(total)\n",
    "\n",
    "        lb_list = [torch.clamp(odi - max_move, 0.0, 1.0) for odi in old_densities_list]\n",
    "        ub_list = [torch.clamp(odi + max_move, 0.0, 1.0) for odi in old_densities_list]\n",
    "\n",
    "        def targets_for_lambda(lmbd: float):\n",
    "            targets = []\n",
    "            flat_all = []\n",
    "            for odi, s, lb, ub in zip(old_densities_list, sensitivities_list, lb_list, ub_list):\n",
    "                Bi = s / (-(dv * lmbd) + 1e-20)\n",
    "                tgt = odi * torch.pow(torch.clamp(Bi, min=1e-20), damping_parameter)\n",
    "                tgt = torch.maximum(lb, torch.minimum(ub, tgt))\n",
    "                tgt = torch.clamp(tgt, 0.0, 1.0)\n",
    "                targets.append(tgt)\n",
    "                flat_all.append(tgt.reshape(-1))\n",
    "            vol = sample_volume * torch.mean(torch.cat(flat_all, dim=0))\n",
    "            return vol, targets\n",
    "\n",
    "        lam_lo, lam_hi = 0.0, 1e9\n",
    "        for _ in range(60):\n",
    "            lam_mid = 0.5 * (lam_lo + lam_hi)\n",
    "            vol_mid, _ = targets_for_lambda(lam_mid)\n",
    "            if (lam_hi - lam_lo) / (lam_hi + lam_lo + 1e-12) < 1e-3:\n",
    "                break\n",
    "            if vol_mid > target_volume:\n",
    "                lam_lo = lam_mid\n",
    "            else:\n",
    "                lam_hi = lam_mid\n",
    "\n",
    "        _, targets = targets_for_lambda(0.5 * (lam_lo + lam_hi))\n",
    "        return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebaa28b",
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1770669020131,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "aebaa28b"
   },
   "outputs": [],
   "source": [
    "class model_training:\n",
    "    def __init__(self,\n",
    "                 u_model,\n",
    "                 v_model,\n",
    "                 w_model,\n",
    "                 density_GINN_model,\n",
    "                 SDF_GINN_model,\n",
    "                 training_hparams,\n",
    "                 topo_hparams,\n",
    "                 constraint_hparams,\n",
    "                 GINN_hparams,\n",
    "                 loss_weight_hparams,\n",
    "                 test_case,\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # ---------------- Device ----------------\n",
    "        self.device = torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available() else\n",
    "            \"mps\" if torch.backends.mps.is_available() else\n",
    "            \"cpu\"\n",
    "        )\n",
    "\n",
    "        # ---------------- Models ----------------\n",
    "        self.u_model = u_model.to(self.device)\n",
    "        self.v_model = v_model.to(self.device)\n",
    "        self.w_model = w_model.to(self.device)\n",
    "        self.density_GINN_model = density_GINN_model.to(self.device)\n",
    "        self.SDF_GINN_model = SDF_GINN_model.to(self.device)\n",
    "\n",
    "        # ---------------- Hparams ----------------\n",
    "        self.topo_hparams = topo_hparams\n",
    "        self.training_hparams = training_hparams\n",
    "        self.test_case = test_case\n",
    "        self.GINN_hparams = GINN_hparams\n",
    "        self.num_points = training_hparams['total_sample_points']\n",
    "        self.batch_size = training_hparams['batch_size']\n",
    "        self.save_path = topo_hparams['save_path']\n",
    "        self.volume_ratio = topo_hparams.get('volume_ratio', None)\n",
    "        self.lr_PINN = topo_hparams['lr_PINN']\n",
    "        self.lr_GINN = topo_hparams['lr_GINN']\n",
    "        self.save_interval = topo_hparams['save_interval']\n",
    "        self.filter_radius = topo_hparams['filter_radius']\n",
    "        self.n_opt_iterations = topo_hparams['n_opt_iterations']\n",
    "        self.n_sim_iterations = topo_hparams['n_sim_iterations']\n",
    "        self.n_pre_training_iterations_PINN = topo_hparams['n_pre_training_iterations_PINN']\n",
    "        self.n_pre_training_iterations_GINN = topo_hparams['n_pre_training_iterations_GINN']\n",
    "        self.n_pre_training_iterations_density_GINN = topo_hparams['n_pre_training_iterations_density_GINN']\n",
    "        self.n_opt_batches = topo_hparams['n_opt_batches']\n",
    "        self.seed = topo_hparams['seed']\n",
    "        self.refine_study = training_hparams[\"refine_study\"]\n",
    "        self.num_points_envelope_loss = GINN_hparams['num_points_envelope_loss']\n",
    "        self.num_points_connectivity_loss = GINN_hparams['num_points_connectivity_loss']\n",
    "        self.envelope_extension_factor = GINN_hparams['envelope_extension_factor']\n",
    "        self.plot_threshold = float(topo_hparams.get('rho_treshold', 0.25))\n",
    "        self.n_eval_points_plot = int(topo_hparams.get('n_eval_points_plot', 400_000))\n",
    "        self.max_batch_plot = int(topo_hparams.get('max_batch_plot', 120_000))\n",
    "        self.csv_ginn_loss_path = os.path.join(self.save_path, \"ginn_losses.csv\")\n",
    "        self.csv_topo_loss_path = os.path.join(self.save_path, \"topo_density_losses.csv\")\n",
    "        self.csv_opt_metrics_path = os.path.join(self.save_path, \"topo_metrics.csv\")\n",
    "        self.csv_opt_loss_path = os.path.join(self.save_path, \"optimization_losses.csv\")\n",
    "        self.csv_eval_metrics_path = os.path.join(self.save_path, \"evaluation_metrics.csv\")\n",
    "        self.eval_metrics_enable = bool(self.topo_hparams.get(\"eval_metrics_enable\", True))\n",
    "        self.eval_grid_n = int(self.topo_hparams.get(\"eval_metrics_grid_n\", 64))\n",
    "        self.eval_batch = int(self.topo_hparams.get(\"eval_metrics_batch\", 200_000))\n",
    "        self.eval_boundary_n = int(self.topo_hparams.get(\"eval_metrics_boundary_n\", 12_000))\n",
    "        self.eval_interface_n = int(self.topo_hparams.get(\"eval_metrics_interface_n\", 8_000))\n",
    "        self.eval_max_boundary_pts = int(self.topo_hparams.get(\"eval_metrics_max_boundary_pts\", 20_000))\n",
    "        self.eval_cdist_chunk = int(self.topo_hparams.get(\"eval_metrics_cdist_chunk\", 4_096))\n",
    "\n",
    "\n",
    "        self.enforce_density = Density_Constraints(\n",
    "            constraint_hparams,\n",
    "            JEB,\n",
    "            JEB.interfaces.is_inside_interface_thickness,\n",
    "            JEB.interfaces.is_inside_prohibited_region\n",
    "        )\n",
    "\n",
    "        # ---------------- ALM setup for first optimization stage ----------------\n",
    "        self.scalar_keys = [\n",
    "            'Objective',\n",
    "            'Envelope Loss',\n",
    "            'Connectivity Loss',\n",
    "            'Prescribed Normals Loss',\n",
    "            'Prescribed Thickness Loss',\n",
    "            'Prohibited Region Loss',\n",
    "            'Smoothness Loss',\n",
    "            'Holes Loss',\n",
    "        ]\n",
    "\n",
    "        lambda_init_geom = {\n",
    "            'Objective': 1.0,\n",
    "            'Envelope Loss':             GINN_hparams.get('envelope_loss_weight', 1.0),\n",
    "            'Connectivity Loss':         GINN_hparams.get('connectivity_loss_weight', 100.0),\n",
    "            'Prescribed Normals Loss':   GINN_hparams.get('prescribed_normals_loss_weight', 1.0),\n",
    "            'Prescribed Thickness Loss': GINN_hparams.get('prescribed_thickness_loss_weight', 1.0),\n",
    "            'Prohibited Region Loss':    GINN_hparams.get('prohibited_region_loss_weight', 1.0),\n",
    "            'Smoothness Loss':           GINN_hparams.get('smoothness_loss_weight', 1e-4),\n",
    "            'Holes Loss':                GINN_hparams.get('holes_loss_weight', 100.0),\n",
    "        }\n",
    "\n",
    "        self.alm = ALM(\n",
    "            loss_keys=self.scalar_keys,\n",
    "            objective_key='Objective',\n",
    "            lambda_dict=lambda_init_geom,\n",
    "            alpha=loss_weight_hparams['alpha'],\n",
    "            gamma=loss_weight_hparams['gamma'],\n",
    "            epsilon=loss_weight_hparams['epsilon'],\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        # ---------------- ALM setup for second optimization stage  ----------------\n",
    "        self.scalar_keys_rho = [\n",
    "            'Topo Objective',\n",
    "            'Density Envelope Loss',\n",
    "            'Density Connectivity Loss'\n",
    "        ]\n",
    "\n",
    "        lambda_init_rho = {\n",
    "            'Topo Objective':            1.0,\n",
    "            'Density Envelope Loss':     GINN_hparams.get('envelope_loss_weight_density', 1.0),\n",
    "            'Density Connectivity Loss': GINN_hparams.get('connectivity_loss_weight_density', 100.0),\n",
    "        }\n",
    "\n",
    "        self.alm_rho = ALM(\n",
    "            loss_keys=self.scalar_keys_rho,\n",
    "            objective_key='Topo Objective',\n",
    "            lambda_dict=lambda_init_rho,\n",
    "            alpha=loss_weight_hparams['alpha'],\n",
    "            gamma=loss_weight_hparams['gamma'],\n",
    "            epsilon=loss_weight_hparams['epsilon'],\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        # ---------------- Gradient clipping ----------------\n",
    "        self.grad_clipper = AutoClip(\n",
    "            grad_clipping_on=training_hparams[\"grad_clipping_on\"],\n",
    "            grad_clip=training_hparams[\"grad_clip\"],\n",
    "            auto_clip_on=training_hparams[\"auto_clip_on\"],\n",
    "            auto_clip_percentile=training_hparams[\"auto_clip_percentile\"],\n",
    "            auto_clip_hist_len=training_hparams[\"auto_clip_hist_len\"],\n",
    "            auto_clip_min_len=training_hparams[\"auto_clip_min_len\"],\n",
    "        )\n",
    "\n",
    "        # ---------------- Samplers ----------------\n",
    "        self.point_sampler = Point_Sampler(\n",
    "            test_case.domain,\n",
    "            test_case.interfaces,\n",
    "            num_points_domain=self.num_points,\n",
    "            num_points_interface=0\n",
    "        )\n",
    "\n",
    "        # PH setup\n",
    "        inside_env_sdf = make_inside_envelope_fn_from_domain(\n",
    "            domain=self.test_case.domain, nx=self.test_case.dim, device=self.device\n",
    "        )\n",
    "        self.PH = PH(\n",
    "            nx=self.test_case.dim,\n",
    "            bounds=self.test_case.domain,\n",
    "            model=self.SDF_GINN_model,\n",
    "            n_grid_points=96,\n",
    "            iso_level=0.0,\n",
    "            target_betti=[1, 0, 0],\n",
    "            maxdim=1,\n",
    "            is_density=False,\n",
    "            inside_envelope_fn=inside_env_sdf,\n",
    "            group_size_fwd_no_grad=32768,\n",
    "            add_frame=True,\n",
    "            hole_level=0.06,\n",
    "            test_case=self.test_case\n",
    "        )\n",
    "\n",
    "        # boundary sampler\n",
    "        interface_points = self.test_case.interfaces.sample_points_from_all_interfaces(\n",
    "            20000, output_type='torch_tensor'\n",
    "        )\n",
    "        self.boundary_sampler = Boundary_Sampler(\n",
    "            dim=self.test_case.dim,\n",
    "            bounds=self.test_case.domain,\n",
    "            model=self.SDF_GINN_model,\n",
    "            x_interface=interface_points,\n",
    "            n_points_surface=20000,\n",
    "            interface_cutoff=0.05\n",
    "        )\n",
    "\n",
    "        # PH setup density\n",
    "        inside_env_density = make_inside_envelope_fn_from_domain(\n",
    "            domain=self.test_case.domain, nx=self.test_case.dim, device=self.device\n",
    "        )\n",
    "        self.PH_density = PH(\n",
    "            nx=self.test_case.dim,\n",
    "            bounds=self.test_case.domain,\n",
    "            model=self.density_GINN_model,\n",
    "            n_grid_points=96,\n",
    "            iso_level=float(self.plot_threshold),\n",
    "            target_betti=[1, 0, 0],\n",
    "            maxdim=1,\n",
    "            is_density=True,\n",
    "            inside_envelope_fn=inside_env_density,\n",
    "            group_size_fwd_no_grad=32768,\n",
    "            add_frame=True,\n",
    "            hole_level=0.06,\n",
    "            test_case=self.test_case\n",
    "        )\n",
    "\n",
    "        self.sigma_allow = float(topo_hparams.get('sigma_allow', 2000.0))\n",
    "        self.stress_tol = float(topo_hparams.get('stress_tol', 0.02))\n",
    "        self.ks_rho = float(topo_hparams.get('ks_rho', 80.0))\n",
    "        self.ks_size_correction = bool(topo_hparams.get('ks_size_correction', False))\n",
    "        self.stress_metric = str(topo_hparams.get('stress_metric', 'KS'))\n",
    "        self.stress_percentile = float(topo_hparams.get('stress_percentile', 0.995))\n",
    "        self.vol_frac_min = float(topo_hparams.get('vol_frac_min', 0.02))\n",
    "        self.vol_frac_max = float(topo_hparams.get('vol_frac_max', 0.98))\n",
    "        self.vol_step_min = float(topo_hparams.get('vol_step_min', 0.005))\n",
    "        self.vol_step_max = float(topo_hparams.get('vol_step_max', 0.05))\n",
    "        self.alpha_decrease = float(topo_hparams.get('alpha_decrease', 0.50))\n",
    "        self.beta_increase = float(topo_hparams.get('beta_increase', 0.25))\n",
    "\n",
    "        self.sigma_ema = None\n",
    "        self.sigma_ema_alpha = 0.2\n",
    "\n",
    "        if getattr(self.density_GINN_model, \"volume_ratio\", None) is None:\n",
    "            self.density_GINN_model.volume_ratio = 0.5\n",
    "\n",
    "\n",
    "        self.hist_iters = []\n",
    "        self.hist_compliance = []\n",
    "        self.hist_volume = []\n",
    "        self.hist_sigma_metric = []\n",
    "        self.hist_sigma_max = []\n",
    "        self.ginn_hist_iters = []\n",
    "        self.ginn_hist_eik = []\n",
    "        self.ginn_hist_env = []\n",
    "        self.ginn_hist_connect = []\n",
    "        self.ginn_hist_hole = []\n",
    "        self.ginn_hist_int = []\n",
    "        self.ginn_hist_norm = []\n",
    "        self.ginn_hist_thick = []\n",
    "        self.ginn_hist_prohib = []\n",
    "        self.ginn_hist_smooth = []\n",
    "        self.ginn_hist_total = []\n",
    "        self.topo_hist_iters = []\n",
    "        self.topo_hist_topo = []\n",
    "        self.topo_hist_env_rho = []\n",
    "        self.topo_hist_conn_rho = []\n",
    "        self.topo_hist_total = []\n",
    "        self.topo_step_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ----- helpers -----------------------\n",
    "\n",
    "    @staticmethod\n",
    "    def loss_ramp_up(epoch: int, start_epoch: int, ramp_epochs: int) -> float:\n",
    "        if epoch < start_epoch:\n",
    "            return 0.0\n",
    "        return float(min(1.0, (epoch - start_epoch + 1) / max(1, ramp_epochs)))\n",
    "\n",
    "    _compute_eval_metrics_3d = compute_eval_metrics_3d\n",
    "    _log_eval_metrics_csv = log_eval_metrics_csv\n",
    "    _log_ginn_losses_csv = log_ginn_losses_csv\n",
    "    _log_topo_density_losses_csv = log_topo_density_losses_csv\n",
    "    _log_optimization_metrics_csv = log_optimization_metrics_csv\n",
    "    _log_optimization_losses_csv = log_optimization_losses_csv\n",
    "    _maybe_log_eval_metrics = maybe_log_eval_metrics\n",
    "    _save_training_curves = save_training_curves\n",
    "    _save_ginn_training_curves = save_ginn_training_curves\n",
    "    _save_topology_density_curves = save_topology_density_curves\n",
    "\n",
    "\n",
    "    def _compute_losses(self, coords, epoch):\n",
    "\n",
    "        geometry = GINN_Losses(\n",
    "            self.SDF_GINN_model,\n",
    "            self.test_case,\n",
    "            self.GINN_hparams,\n",
    "            self.PH,\n",
    "            self.boundary_sampler,\n",
    "            self.enforce_density\n",
    "        )\n",
    "\n",
    "        w = self.GINN_hparams\n",
    "        ph_ramp = self.loss_ramp_up(epoch, start_epoch=0, ramp_epochs=550)\n",
    "\n",
    "        # weighted components\n",
    "        eik     = geometry.eikonal_loss(coords)              * w['eikonal_loss_weight']\n",
    "        intr    = geometry.interface_loss()                  * w['interface_loss_weight']\n",
    "        env     = geometry.design_envelope_loss()            * w['envelope_loss_weight']\n",
    "        conn    = geometry.connectivity_loss()               * (w['connectivity_loss_weight'] * ph_ramp)\n",
    "        norm    = geometry.surface_normal_loss()             * w['prescribed_normals_loss_weight']\n",
    "        thick   = geometry.prescribed_thickness_loss(coords) * w['prescribed_thickness_loss_weight']\n",
    "        prohib  = geometry.prohibited_region_loss(coords)    * w['prohibited_region_loss_weight']\n",
    "\n",
    "        smooth0 = geometry.smoothness_loss(epoch)            * w['smoothness_loss_weight']\n",
    "        smooth  = self.loss_ramp_up(epoch, w['curv_start_epoch'], w['curv_ramp_epochs']) * smooth0\n",
    "\n",
    "        holes   = geometry.holes_loss()                      * (w['holes_loss_weight'] * ph_ramp)\n",
    "\n",
    "        objective = eik + intr\n",
    "\n",
    "        return {\n",
    "            'Objective':                 torch.relu(objective),\n",
    "            'Envelope Loss':             torch.relu(env),\n",
    "            'Connectivity Loss':         torch.relu(conn),\n",
    "            'Prescribed Normals Loss':   torch.relu(norm),\n",
    "            'Prescribed Thickness Loss': torch.relu(thick),\n",
    "            'Prohibited Region Loss':    torch.relu(prohib),\n",
    "            'Smoothness Loss':           torch.relu(smooth),\n",
    "            'Holes Loss':                torch.relu(holes),\n",
    "        }\n",
    "\n",
    "    def _compute_density_topology_ALM_losses(self, coords, target_densities):\n",
    "\n",
    "        coords = coords.to(self.device)\n",
    "        target_densities = target_densities.to(self.device)\n",
    "\n",
    "        rho = self.density_GINN_model(coords)\n",
    "        topo_obj = F.mse_loss(rho, target_densities)\n",
    "\n",
    "        self.PH_density.invalidate_cache()\n",
    "\n",
    "        geometry_rho = GINN_Losses(\n",
    "            self.density_GINN_model,\n",
    "            self.test_case,\n",
    "            self.GINN_hparams,\n",
    "            self.PH_density,\n",
    "            self.boundary_sampler,\n",
    "            self.enforce_density\n",
    "        )\n",
    "\n",
    "        env_rho = geometry_rho.design_envelope_loss_from_density(\n",
    "            density_model=self.density_GINN_model,\n",
    "            iso_level=float(self.plot_threshold)\n",
    "        )\n",
    "\n",
    "        conn_rho = geometry_rho.connectivity_loss_from_density(\n",
    "            density_model=self.density_GINN_model,\n",
    "            iso_level=float(self.plot_threshold)\n",
    "        )\n",
    "\n",
    "        losses_rho = {\n",
    "            'Topo Objective':            torch.relu(topo_obj),\n",
    "            'Density Envelope Loss':     torch.relu(env_rho),\n",
    "            'Density Connectivity Loss': torch.relu(conn_rho),\n",
    "        }\n",
    "\n",
    "        return losses_rho, topo_obj.detach(), env_rho.detach(), conn_rho.detach()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _safe_clip_ratio(v, lo, hi, eps=1e-3):\n",
    "        lo = max(lo, eps)\n",
    "        hi = min(hi, 1.0 - eps)\n",
    "        return float(np.clip(v, lo, hi))\n",
    "\n",
    "\n",
    "    def _estimate_compliance_internal_energy_3d(self, n_opt_cells):\n",
    "\n",
    "        self.u_model.eval()\n",
    "        self.v_model.eval()\n",
    "        self.w_model.eval()\n",
    "        self.density_GINN_model.eval()\n",
    "\n",
    "        nx, ny, nz = n_opt_cells\n",
    "        xs = get_grid_centers(JEB.domain, [nx, ny, nz]).astype(np.float32)\n",
    "        xt = torch.tensor(xs, dtype=torch.float32, device=self.device, requires_grad=True)\n",
    "\n",
    "        rho = self.density_GINN_model(xt)\n",
    "        rho, _ = self.enforce_density.apply(xt, rho, None, n_opt_cells, JEB.domain)\n",
    "        r = rho.view(-1).clamp(0.0, 1.0)\n",
    "\n",
    "        u = self.u_model(xt)\n",
    "        v = self.v_model(xt)\n",
    "        w = self.w_model(xt)\n",
    "\n",
    "        gu = torch.autograd.grad(u, xt, grad_outputs=torch.ones_like(u), create_graph=False, retain_graph=True)[0]\n",
    "        gv = torch.autograd.grad(v, xt, grad_outputs=torch.ones_like(v), create_graph=False, retain_graph=True)[0]\n",
    "        gw = torch.autograd.grad(w, xt, grad_outputs=torch.ones_like(w), create_graph=False, retain_graph=False)[0]\n",
    "\n",
    "        e11 = gu[:, 0]\n",
    "        e22 = gv[:, 1]\n",
    "        e33 = gw[:, 2]\n",
    "        e12 = 0.5 * (gu[:, 1] + gv[:, 0])\n",
    "        e13 = 0.5 * (gu[:, 2] + gw[:, 0])\n",
    "        e23 = 0.5 * (gv[:, 2] + gw[:, 1])\n",
    "        tr = e11 + e22 + e33\n",
    "\n",
    "        p = float(self.training_hparams['density_exponent'])\n",
    "        lam0 = Properties(JEB).lame_lambda\n",
    "        mu0 = Properties(JEB).lame_mu\n",
    "        lam = r.pow(p) * lam0\n",
    "        mu = r.pow(p) * mu0\n",
    "\n",
    "        s11 = 2.0 * mu * e11 + lam * tr\n",
    "        s22 = 2.0 * mu * e22 + lam * tr\n",
    "        s33 = 2.0 * mu * e33 + lam * tr\n",
    "        s12 = 2.0 * mu * e12\n",
    "        s13 = 2.0 * mu * e13\n",
    "        s23 = 2.0 * mu * e23\n",
    "\n",
    "        sed = 0.5 * (s11 * e11 + s22 * e22 + s33 * e33 + 2.0 * s12 * e12 + 2.0 * s13 * e13 + 2.0 * s23 * e23)\n",
    "        internal_energy = float(JEB.domain_volume) * sed.mean()\n",
    "        return float(internal_energy.detach().cpu().item())\n",
    "\n",
    "    # ---- stress/volume measurement ------\n",
    "    def _measure_stress_volume_KS_3d(self):\n",
    "        \"\"\"\n",
    "        Binary-geometry evaluation\n",
    "        \"\"\"\n",
    "\n",
    "        ps = Point_Sampler(\n",
    "            JEB.domain, JEB.interfaces,\n",
    "            num_points_domain=self.n_eval_points_plot, num_points_interface=0\n",
    "        )\n",
    "        pts_full = next(ps).to(self.device)\n",
    "\n",
    "        prev = self.density_GINN_model.training\n",
    "        self.density_GINN_model.eval()\n",
    "        with torch.no_grad():\n",
    "            rho = self.density_GINN_model(pts_full).view(-1)\n",
    "        if prev:\n",
    "            self.density_GINN_model.train()\n",
    "\n",
    "        solid_mask = (rho >= self.plot_threshold)\n",
    "\n",
    "        n_total = pts_full.shape[0]\n",
    "        n_solid = int(solid_mask.sum().item())\n",
    "        vol_abs = float(JEB.domain_volume) * (n_solid / max(1, n_total))\n",
    "\n",
    "        if n_solid == 0:\n",
    "            return 0.0, 0.0, vol_abs\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            x = pts_full[solid_mask].clone().detach().requires_grad_(True)\n",
    "\n",
    "            self.u_model.eval()\n",
    "            self.v_model.eval()\n",
    "            self.w_model.eval()\n",
    "\n",
    "            u = self.u_model(x) * JEB.domain_scaling_factor\n",
    "            v = self.v_model(x) * JEB.domain_scaling_factor\n",
    "            w = self.w_model(x) * JEB.domain_scaling_factor\n",
    "\n",
    "            gu = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=False, retain_graph=False)[0]\n",
    "            gv = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=False, retain_graph=False)[0]\n",
    "            gw = torch.autograd.grad(w, x, grad_outputs=torch.ones_like(w), create_graph=False, retain_graph=False)[0]\n",
    "\n",
    "            e11 = gu[:, 0]\n",
    "            e22 = gv[:, 1]\n",
    "            e33 = gw[:, 2]\n",
    "            e12 = 0.5 * (gu[:, 1] + gv[:, 0])\n",
    "            e13 = 0.5 * (gu[:, 2] + gw[:, 0])\n",
    "            e23 = 0.5 * (gv[:, 2] + gw[:, 1])\n",
    "            tr = e11 + e22 + e33\n",
    "\n",
    "            props = Properties(JEB)\n",
    "            lam = props.lame_lambda.to(self.device)\n",
    "            mu = props.lame_mu.to(self.device)\n",
    "\n",
    "            s11 = 2 * mu * e11 + lam * tr\n",
    "            s22 = 2 * mu * e22 + lam * tr\n",
    "            s33 = 2 * mu * e33 + lam * tr\n",
    "            s12 = 2 * mu * e12\n",
    "            s13 = 2 * mu * e13\n",
    "            s23 = 2 * mu * e23\n",
    "\n",
    "            vm2 = 0.5 * ((s11 - s22) ** 2 + (s22 - s33) ** 2 + (s33 - s11) ** 2) + 3 * (s12 ** 2 + s13 ** 2 + s23 ** 2)\n",
    "            vm = torch.sqrt(torch.clamp(vm2, min=1e-32)) * JEB.domain_scaling_factor\n",
    "\n",
    "        s = vm.detach().cpu().numpy().astype(np.float64)\n",
    "        g = s / float(self.sigma_allow) - 1.0\n",
    "        gmax = float(np.max(g))\n",
    "        lse = gmax + (1.0 / self.ks_rho) * float(np.log(np.sum(np.exp(self.ks_rho * (g - gmax))) + 1e-300))\n",
    "        if self.ks_size_correction and s.size > 0:\n",
    "            lse -= (1.0 / self.ks_rho) * float(np.log(s.size))\n",
    "\n",
    "        ks_val = lse\n",
    "        sigma_metric = float(self.sigma_allow) * (1.0 + ks_val)\n",
    "        sigma_max = float(np.max(s))\n",
    "        return sigma_metric, sigma_max, vol_abs\n",
    "\n",
    "    def _measure_stress_volume_percentile_3d(self):\n",
    "\n",
    "        ps = Point_Sampler(\n",
    "            JEB.domain, JEB.interfaces,\n",
    "            num_points_domain=self.n_eval_points_plot, num_points_interface=0\n",
    "        )\n",
    "        pts_full = next(ps).to(self.device)\n",
    "\n",
    "        prev = self.density_GINN_model.training\n",
    "        self.density_GINN_model.eval()\n",
    "        with torch.no_grad():\n",
    "            rho = self.density_GINN_model(pts_full).view(-1)\n",
    "        if prev:\n",
    "            self.density_GINN_model.train()\n",
    "\n",
    "        solid_mask = (rho >= self.plot_threshold)\n",
    "        if not torch.any(solid_mask):\n",
    "            q = torch.quantile(rho, 0.9)\n",
    "            solid_mask = (rho >= q)\n",
    "\n",
    "        n_total = pts_full.shape[0]\n",
    "        n_solid = int(solid_mask.sum().item())\n",
    "        vol_abs = float(JEB.domain_volume) * (n_solid / max(1, n_total))\n",
    "\n",
    "        if n_solid == 0:\n",
    "            return 0.0, 0.0, vol_abs\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            x = pts_full[solid_mask].clone().detach().requires_grad_(True)\n",
    "\n",
    "            self.u_model.eval()\n",
    "            self.v_model.eval()\n",
    "            self.w_model.eval()\n",
    "\n",
    "            u = self.u_model(x) * JEB.domain_scaling_factor\n",
    "            v = self.v_model(x) * JEB.domain_scaling_factor\n",
    "            w = self.w_model(x) * JEB.domain_scaling_factor\n",
    "\n",
    "            gu = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=False, retain_graph=False)[0]\n",
    "            gv = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=False, retain_graph=False)[0]\n",
    "            gw = torch.autograd.grad(w, x, grad_outputs=torch.ones_like(w), create_graph=False, retain_graph=False)[0]\n",
    "\n",
    "            e11 = gu[:, 0]\n",
    "            e22 = gv[:, 1]\n",
    "            e33 = gw[:, 2]\n",
    "            e12 = 0.5 * (gu[:, 1] + gv[:, 0])\n",
    "            e13 = 0.5 * (gu[:, 2] + gw[:, 0])\n",
    "            e23 = 0.5 * (gv[:, 2] + gw[:, 1])\n",
    "            tr = e11 + e22 + e33\n",
    "\n",
    "            props = Properties(JEB)\n",
    "            lam = props.lame_lambda.to(self.device)\n",
    "            mu = props.lame_mu.to(self.device)\n",
    "\n",
    "            s11 = 2 * mu * e11 + lam * tr\n",
    "            s22 = 2 * mu * e22 + lam * tr\n",
    "            s33 = 2 * mu * e33 + lam * tr\n",
    "            s12 = 2 * mu * e12\n",
    "            s13 = 2 * mu * e13\n",
    "            s23 = 2 * mu * e23\n",
    "\n",
    "            vm2 = 0.5 * ((s11 - s22) ** 2 + (s22 - s33) ** 2 + (s33 - s11) ** 2) + 3 * (s12 ** 2 + s13 ** 2 + s23 ** 2)\n",
    "            vm = torch.sqrt(torch.clamp(vm2, min=1e-32)) * JEB.domain_scaling_factor\n",
    "\n",
    "        s = vm.detach().cpu().numpy().astype(np.float64)\n",
    "        q = float(np.clip(self.stress_percentile, 0.0, 1.0))\n",
    "        sigma_metric = float(np.quantile(s, q)) if s.size else 0.0\n",
    "        sigma_max = float(np.max(s)) if s.size else 0.0\n",
    "        return sigma_metric, sigma_max, vol_abs\n",
    "\n",
    "    def _measure_stress_volume_sigma_max_3d(self):\n",
    "\n",
    "        _, sigma_max, vol_abs = self._measure_stress_volume_percentile_3d()\n",
    "        sigma_metric = sigma_max\n",
    "        return sigma_metric, sigma_max, vol_abs\n",
    "\n",
    "    def _measure_stress_volume_3d(self):\n",
    "\n",
    "        metric = str(getattr(self, \"stress_metric\", \"ks\")).lower()\n",
    "        if metric == \"ks\":\n",
    "            return self._measure_stress_volume_KS_3d()\n",
    "        elif metric == \"percentile\":\n",
    "            return self._measure_stress_volume_percentile_3d()\n",
    "        elif metric == \"sigma_max\":\n",
    "            return self._measure_stress_volume_sigma_max_3d()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unknown stress metric: {metric}. \"\n",
    "                f\"Choose between 'ks', 'percentile', and 'sigma_max'.\"\n",
    "            )\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # training steps\n",
    "    # ----------------------------------------------------------------------\n",
    "\n",
    "    def shape_generation_step(self, optimizer, epoch):\n",
    "\n",
    "        if self.refine_study == True: # initialize from pretrained model\n",
    "            model_file = \"/content/gdrive/Othercomputers/Code/JEB_topo/model-000150.pt\"\n",
    "            checkpoint = torch.load(model_file, map_location=self.device)\n",
    "            self.SDF_GINN_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else: #normal training setup\n",
    "            batch_points = next(self.point_sampler)\n",
    "            dataset = TensorDataset(batch_points)\n",
    "            loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "            for _, pts in enumerate(loader):\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                points = pts[0].to(self.device)\n",
    "                self.PH.invalidate_cache()\n",
    "\n",
    "                losses = self._compute_losses(points.clone().detach().requires_grad_(True), epoch)\n",
    "\n",
    "                total_loss = self.alm.build(losses)\n",
    "                total_loss.backward()\n",
    "\n",
    "                if getattr(self, \"grad_clipper\", None) is not None and self.grad_clipper.grad_clip_enabled:\n",
    "                    total_sq = 0.0\n",
    "                    for p in self.SDF_GINN_model.parameters():\n",
    "                        if p.grad is not None:\n",
    "                            g = p.grad.data\n",
    "                            if torch.isfinite(g).all():\n",
    "                                total_sq += g.float().pow(2).sum().item()\n",
    "                    grad_norm = math.sqrt(total_sq)\n",
    "                    self.grad_clipper.update_gradient_norm_history(grad_norm)\n",
    "                    clip_val = self.grad_clipper.get_clip_value()\n",
    "                    if np.isfinite(clip_val):\n",
    "                        torch.nn.utils.clip_grad_norm_(self.SDF_GINN_model.parameters(), clip_val)\n",
    "\n",
    "                optimizer.step()\n",
    "                self.alm.update(losses)\n",
    "\n",
    "    def density_PINN_initialization_step(self, coords, density_GINN_optimizer):\n",
    "\n",
    "        self.density_GINN_model.train()\n",
    "        self.SDF_GINN_model.eval()\n",
    "\n",
    "        sdf = self.SDF_GINN_model(coords)\n",
    "        sdf = torch.sigmoid(-1000 * sdf).detach()\n",
    "        topo_initial_density = torch.clamp(sdf, 0.0, 0.5)\n",
    "\n",
    "        rho = self.density_GINN_model(coords)\n",
    "        initial_density_loss = F.mse_loss(rho, topo_initial_density)\n",
    "\n",
    "        density_GINN_optimizer.zero_grad(set_to_none=True)\n",
    "        initial_density_loss.backward()\n",
    "        density_GINN_optimizer.step()\n",
    "\n",
    "    def PINN_update_step(self, coords, PINN_optimizer, n_opt_samples):\n",
    "\n",
    "        self.u_model.train()\n",
    "        self.v_model.train()\n",
    "        self.w_model.train()\n",
    "        self.density_GINN_model.eval()\n",
    "\n",
    "        physics_loss = PINN_losses(\n",
    "            self.u_model,\n",
    "            self.v_model,\n",
    "            self.w_model,\n",
    "            self.density_GINN_model,\n",
    "            n_opt_samples,\n",
    "            self.training_hparams,\n",
    "            self.enforce_density\n",
    "        )\n",
    "\n",
    "        PINN_optimizer.zero_grad(set_to_none=True)\n",
    "        loss = physics_loss.ritz_loss(coords)\n",
    "        loss.backward()\n",
    "        PINN_optimizer.step()\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "    def topology_optimization_step(self, density_GINN_optimizer, coords, target_densities):\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        self.density_GINN_model.train()\n",
    "        density_GINN_optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        losses_rho, topo_obj_raw, env_raw, conn_raw = self._compute_density_topology_ALM_losses(\n",
    "              coords, target_densities\n",
    "          )\n",
    "\n",
    "        if self.GINN_hparams['envelope_loss_weight_density']== 0:\n",
    "          densities = self.density_GINN_model(coords)\n",
    "          total_loss = F.mse_loss(densities, target_densities)\n",
    "        else:\n",
    "          total_loss = self.alm_rho.build(losses_rho)\n",
    "\n",
    "        self.topo_step_counter += 1\n",
    "        self.topo_hist_iters.append(self.topo_step_counter)\n",
    "\n",
    "        topo_val = float(topo_obj_raw.item())\n",
    "        env_val = float(env_raw.item())\n",
    "        conn_val = float(conn_raw.item())\n",
    "\n",
    "        self.topo_hist_topo.append(topo_val)\n",
    "        self.topo_hist_env_rho.append(env_val)\n",
    "        self.topo_hist_conn_rho.append(conn_val)\n",
    "\n",
    "        total_raw = topo_val + env_val + conn_val\n",
    "        self.topo_hist_total.append(total_raw)\n",
    "\n",
    "        self._log_topo_density_losses_csv(\n",
    "            step=self.topo_step_counter,\n",
    "            topo_obj=topo_val,\n",
    "            env_rho=env_val,\n",
    "            conn_rho=conn_val,\n",
    "            total_raw=total_raw\n",
    "        )\n",
    "\n",
    "        total_loss.backward()\n",
    "\n",
    "        if getattr(self, \"grad_clipper\", None) is not None and self.grad_clipper.grad_clip_enabled:\n",
    "            total_sq = 0.0\n",
    "            for p in self.density_GINN_model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    g = p.grad.data\n",
    "                    if torch.isfinite(g).all():\n",
    "                        total_sq += g.float().pow(2).sum().item()\n",
    "            grad_norm = math.sqrt(total_sq)\n",
    "            self.grad_clipper.update_gradient_norm_history(grad_norm)\n",
    "            clip_val = self.grad_clipper.get_clip_value()\n",
    "            if np.isfinite(clip_val):\n",
    "                torch.nn.utils.clip_grad_norm_(self.density_GINN_model.parameters(), clip_val)\n",
    "\n",
    "        density_GINN_optimizer.step()\n",
    "\n",
    "        self.alm_rho.update(losses_rho)\n",
    "\n",
    "        _ = time.perf_counter() - t0\n",
    "        return None\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # main driver\n",
    "    # ----------------------------------------------------------------------\n",
    "    def generate_geometry(self):\n",
    "\n",
    "        set_random_seed(self.seed)\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "        DEFAULT_N_SIM_SAMPLES_2D = 300000\n",
    "        DEFAULT_N_OPT_SAMPLES_2D = 300000\n",
    "\n",
    "        n_sim_samples = get_default_sample_counts(JEB.domain, DEFAULT_N_SIM_SAMPLES_2D)\n",
    "        n_opt_samples = get_default_sample_counts(JEB.domain, DEFAULT_N_OPT_SAMPLES_2D)\n",
    "\n",
    "        PINN_model_params_list = (\n",
    "            list(self.u_model.parameters()) +\n",
    "            list(self.v_model.parameters()) +\n",
    "            list(self.w_model.parameters())\n",
    "        )\n",
    "        PINN_optimizer = torch.optim.Adam(PINN_model_params_list, lr=self.lr_PINN, betas=(0.9, 0.99))\n",
    "        density_GINN_optimizer = torch.optim.Adam(self.density_GINN_model.parameters(), lr=self.lr_GINN, betas=(0.8, 0.9))\n",
    "        SDF_GINN_optimizer = torch.optim.Adam(self.SDF_GINN_model.parameters(), lr=self.lr_GINN)\n",
    "\n",
    "        PINN_point_sampler = gen_samples(JEB.domain, n_sim_samples)\n",
    "        GINN_point_sampler = gen_samples(JEB.domain, n_opt_samples)\n",
    "\n",
    "        # ===================== (1) SDF-GINN pre-training =====================\n",
    "        print(\"=== Generating Geometry (SDF pre-training) ===\")\n",
    "\n",
    "        ginn_log_interval = int(self.topo_hparams.get(\"ginn_log_interval\", 50))\n",
    "\n",
    "        for it in tqdm(range(self.n_pre_training_iterations_GINN), desc=\"GINN Training\"):\n",
    "            _ = next(GINN_point_sampler)  \n",
    "            self.shape_generation_step(optimizer=SDF_GINN_optimizer, epoch=it)\n",
    "\n",
    "\n",
    "            if (it % ginn_log_interval) == 0:\n",
    "                try:\n",
    "                    point_sampler = Point_Sampler(JEB.domain, JEB.interfaces, num_points_domain=400000, num_points_interface=0)\n",
    "                    coords_dbg = next(point_sampler).to(self.device)\n",
    "                    self.SDF_GINN_model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        SDF = self.SDF_GINN_model(coords_dbg).squeeze(-1)\n",
    "\n",
    "                    coords_cpu = coords_dbg.detach().cpu()\n",
    "                    SDF_cpu = SDF.detach().cpu()\n",
    "\n",
    "                    tolerance = 1e-6\n",
    "                    mask = (SDF_cpu <= tolerance)\n",
    "                    if mask.sum().item() == 0:\n",
    "                        idx = torch.argmin(torch.abs(SDF_cpu))\n",
    "                        mask[idx] = True\n",
    "\n",
    "                    pts_in = coords_cpu[mask]\n",
    "                    sdf_in = SDF_cpu[mask]\n",
    "\n",
    "                    scatter_in = go.Scatter3d(\n",
    "                        x=pts_in[:, 0].numpy(),\n",
    "                        y=pts_in[:, 1].numpy(),\n",
    "                        z=pts_in[:, 2].numpy(),\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=2,\n",
    "                            color=sdf_in.numpy(),\n",
    "                            colorscale='Reds',\n",
    "                            cmin=float(SDF_cpu.min()),\n",
    "                            cmax=0.0,\n",
    "                            opacity=1.0\n",
    "                        ),\n",
    "                        name='SDF ≤ 0'\n",
    "                    )\n",
    "\n",
    "                    fig = go.Figure(data=[scatter_in])\n",
    "                    fig.update_layout(\n",
    "                        scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z', aspectmode='data'),\n",
    "                        margin=dict(l=0, r=0, b=0, t=30),\n",
    "                        title=\"Inside points by SDF (SDF ≤ 0)\"\n",
    "                    )\n",
    "                    fig.show()\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                save_sdf_outputs_3d(\n",
    "                    self.SDF_GINN_model,\n",
    "                    JEB.domain,\n",
    "                    n_opt_samples,\n",
    "                    self.save_path,\n",
    "                    save_prefix='',\n",
    "                    save_postfix=f'-ginn-{it:06d}',\n",
    "                    iso_level=0.0,\n",
    "                    device=self.device,\n",
    "                    enforce_density=None,\n",
    "                    tag='sdf-raw'\n",
    "                )\n",
    "                save_sdf_outputs_3d(\n",
    "                    self.SDF_GINN_model,\n",
    "                    JEB.domain,\n",
    "                    n_opt_samples,\n",
    "                    self.save_path,\n",
    "                    save_prefix='',\n",
    "                    save_postfix=f'-ginn-{it:06d}',\n",
    "                    iso_level=0.0,\n",
    "                    device=self.device,\n",
    "                    enforce_density=self.enforce_density,\n",
    "                    tag='sdf-constrained'\n",
    "                )\n",
    "\n",
    "                geometry_losses = GINN_Losses(\n",
    "                    self.SDF_GINN_model,\n",
    "                    self.test_case,\n",
    "                    self.GINN_hparams,\n",
    "                    self.PH,\n",
    "                    self.boundary_sampler,\n",
    "                    self.enforce_density\n",
    "                )\n",
    "\n",
    "                coords_eval = next(self.point_sampler).to(self.device)\n",
    "\n",
    "                eik_loss = geometry_losses.eikonal_loss(coords_eval)\n",
    "                env_loss = geometry_losses.design_envelope_loss()\n",
    "                connect_loss = geometry_losses.connectivity_loss()\n",
    "                hole_loss = geometry_losses.holes_loss()\n",
    "                int_loss = geometry_losses.interface_loss()\n",
    "                norm_loss = geometry_losses.surface_normal_loss()\n",
    "                thick_loss = geometry_losses.prescribed_thickness_loss(coords_eval)\n",
    "                prohib_loss = geometry_losses.prohibited_region_loss(coords_eval)\n",
    "                smooth_raw = geometry_losses.smoothness_loss(it)\n",
    "\n",
    "                smooth_loss_scaled = self.loss_ramp_up(\n",
    "                    it,\n",
    "                    self.GINN_hparams['curv_start_epoch'],\n",
    "                    self.GINN_hparams['curv_ramp_epochs']\n",
    "                ) * smooth_raw\n",
    "\n",
    "                total_loss = (\n",
    "                    eik_loss + env_loss + connect_loss + hole_loss + int_loss +\n",
    "                    norm_loss + thick_loss + prohib_loss + smooth_loss_scaled\n",
    "                )\n",
    "\n",
    "                self.ginn_hist_iters.append(it)\n",
    "                self.ginn_hist_eik.append(eik_loss.item())\n",
    "                self.ginn_hist_env.append(env_loss.item())\n",
    "                self.ginn_hist_connect.append(connect_loss.item())\n",
    "                self.ginn_hist_hole.append(hole_loss.item())\n",
    "                self.ginn_hist_int.append(int_loss.item())\n",
    "                self.ginn_hist_norm.append(norm_loss.item())\n",
    "                self.ginn_hist_thick.append(thick_loss.item())\n",
    "                self.ginn_hist_prohib.append(prohib_loss.item())\n",
    "                self.ginn_hist_smooth.append(smooth_loss_scaled.item())\n",
    "                self.ginn_hist_total.append(total_loss.item())\n",
    "\n",
    "                self._log_ginn_losses_csv(\n",
    "                    it,\n",
    "                    eik_loss.item(),\n",
    "                    env_loss.item(),\n",
    "                    connect_loss.item(),\n",
    "                    hole_loss.item(),\n",
    "                    int_loss.item(),\n",
    "                    norm_loss.item(),\n",
    "                    thick_loss.item(),\n",
    "                    prohib_loss.item(),\n",
    "                    smooth_loss_scaled.item(),\n",
    "                    total_loss.item()\n",
    "                )\n",
    "\n",
    "                self._save_ginn_training_curves(it)\n",
    "                self._maybe_log_eval_metrics(phase=\"GINN\", it=it, model_kind=\"sdf\")\n",
    "\n",
    "        final_it = int(self.n_pre_training_iterations_GINN - 1)\n",
    "        if len(self.ginn_hist_iters) == 0 or int(self.ginn_hist_iters[-1]) != final_it:\n",
    "            geometry_losses = GINN_Losses(\n",
    "                self.SDF_GINN_model,\n",
    "                self.test_case,\n",
    "                self.GINN_hparams,\n",
    "                self.PH,\n",
    "                self.boundary_sampler,\n",
    "                self.enforce_density\n",
    "            )\n",
    "            coords_eval = next(self.point_sampler).to(self.device)\n",
    "\n",
    "            eik_loss = geometry_losses.eikonal_loss(coords_eval)\n",
    "            env_loss = geometry_losses.design_envelope_loss()\n",
    "            connect_loss = geometry_losses.connectivity_loss()\n",
    "            hole_loss = geometry_losses.holes_loss()\n",
    "            int_loss = geometry_losses.interface_loss()\n",
    "            norm_loss = geometry_losses.surface_normal_loss()\n",
    "            thick_loss = geometry_losses.prescribed_thickness_loss(coords_eval)\n",
    "            prohib_loss = geometry_losses.prohibited_region_loss(coords_eval)\n",
    "            smooth_raw = geometry_losses.smoothness_loss(final_it)\n",
    "\n",
    "            smooth_loss_scaled = self.loss_ramp_up(\n",
    "                final_it,\n",
    "                self.GINN_hparams['curv_start_epoch'],\n",
    "                self.GINN_hparams['curv_ramp_epochs']\n",
    "            ) * smooth_raw\n",
    "\n",
    "            total_loss = (\n",
    "                eik_loss + env_loss + connect_loss + hole_loss + int_loss +\n",
    "                norm_loss + thick_loss + prohib_loss + smooth_loss_scaled\n",
    "            )\n",
    "\n",
    "            self._log_ginn_losses_csv(\n",
    "                final_it,\n",
    "                eik_loss.item(),\n",
    "                env_loss.item(),\n",
    "                connect_loss.item(),\n",
    "                hole_loss.item(),\n",
    "                int_loss.item(),\n",
    "                norm_loss.item(),\n",
    "                thick_loss.item(),\n",
    "                prohib_loss.item(),\n",
    "                smooth_loss_scaled.item(),\n",
    "                total_loss.item()\n",
    "            )\n",
    "\n",
    "            self._maybe_log_eval_metrics(phase=\"GINN\", it=final_it, model_kind=\"sdf\")\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # ---- Initialize volume_ratio ------\n",
    "        grid_xyz = get_grid_centers(JEB.domain, n_opt_samples).astype(np.float32)\n",
    "        xt = torch.tensor(grid_xyz, dtype=torch.float32, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            sdf_field = self.SDF_GINN_model(xt).squeeze()\n",
    "            occ = torch.sigmoid(-1000 * sdf_field).clamp(0, 1)\n",
    "            init_vol_frac = float(occ.mean().item())\n",
    "\n",
    "        start_ratio = self.volume_ratio if (self.volume_ratio is not None) else init_vol_frac\n",
    "        self.volume_ratio = self._safe_clip_ratio(start_ratio, self.vol_frac_min, self.vol_frac_max)\n",
    "        self.density_GINN_model.volume_ratio = float(self.volume_ratio)\n",
    "        target_volume = float(self.volume_ratio) * float(JEB.domain_volume)\n",
    "\n",
    "        # ===================== (2) density-GINN init =====================\n",
    "        print(\"=== Pre-Training density GINN ===\")\n",
    "        for _ in tqdm(range(self.n_pre_training_iterations_density_GINN), desc=\"density-GINN Init\"):\n",
    "            coords = next(GINN_point_sampler)\n",
    "            self.density_PINN_initialization_step(coords, density_GINN_optimizer)\n",
    "        print()\n",
    "\n",
    "        # ===================== (3) PINN warm-up =====================\n",
    "        print(\"=== Pre-Training PINN ===\")\n",
    "        for _ in tqdm(range(self.n_pre_training_iterations_PINN), desc=\"PINN Pre-Training\"):\n",
    "            coords = next(PINN_point_sampler)\n",
    "            self.PINN_update_step(coords, PINN_optimizer, n_sim_samples)\n",
    "        print()\n",
    "\n",
    "        # ---- Initial geometry saves (OBJ + iso) ----\n",
    "        save_density_outputs_3d(\n",
    "            self.density_GINN_model, JEB.domain, n_opt_samples,\n",
    "            self.enforce_density, self.save_path, '',\n",
    "            '-initial', iso_level=self.plot_threshold\n",
    "        )\n",
    "        save_density_outputs_3d_unconstrained(\n",
    "            self.density_GINN_model, JEB.domain, n_opt_samples,\n",
    "            self.save_path, '', '-initial', iso_level=self.plot_threshold\n",
    "        )\n",
    "\n",
    "        print('Saved initial geometry to', self.save_path)\n",
    "\n",
    "        pts0, u0p, v0p, w0p, vm0p = predict_uvw_sigma_points_3d(\n",
    "            self.u_model, self.v_model, self.w_model, self.density_GINN_model,\n",
    "            rho_threshold_plot=self.plot_threshold,\n",
    "            n_eval_points=self.n_eval_points_plot,\n",
    "            max_batch=self.max_batch_plot,\n",
    "            device=self.device,\n",
    "            test_case=self.test_case\n",
    "        )\n",
    "        png0 = os.path.join(self.save_path, f\"uvwvm-{0:06d}.png\")\n",
    "        save_uvw_sigma_to_file_3d(pts0, u0p, v0p, w0p, vm0p, png0, title=\"Iteration 0\")\n",
    "\n",
    "        sigma_metric0, sigma_max0, vol0 = self._measure_stress_volume_3d()\n",
    "        comp0 = self._estimate_compliance_internal_energy_3d(n_opt_samples)\n",
    "\n",
    "        self.hist_iters.append(0)\n",
    "        self.hist_sigma_metric.append(sigma_metric0)\n",
    "        self.hist_sigma_max.append(sigma_max0)\n",
    "        self.hist_volume.append(vol0)\n",
    "        self.hist_compliance.append(comp0)\n",
    "\n",
    "        self._save_training_curves(0)\n",
    "        self._log_optimization_metrics_csv(0, sigma_metric0, sigma_max0, vol0, comp0)\n",
    "        self._maybe_log_eval_metrics(phase=\"TOPO\", it=0, model_kind=\"density\")\n",
    "        self.sigma_ema = sigma_metric0\n",
    "\n",
    "        # ===================== Second optimization stage =====================\n",
    "        for it in range(1, self.n_opt_iterations + 1):\n",
    "            print(f\"\\n=== Optimization iteration {it}/{self.n_opt_iterations} ===\")\n",
    "\n",
    "            # ---- Volume controller ---------\n",
    "            r = self.sigma_ema / (self.sigma_allow + 1e-20)\n",
    "\n",
    "            if r < 1.0 - self.stress_tol:\n",
    "                gap = 1.0 - r\n",
    "                step = float(np.clip(self.alpha_decrease * gap, self.vol_step_min, self.vol_step_max))\n",
    "                new_ratio = float(self.volume_ratio) * (1.0 - step)\n",
    "            elif r > 1.0 + self.stress_tol:\n",
    "                gap = r - 1.0\n",
    "                step = float(np.clip(self.beta_increase * gap, self.vol_step_min, self.vol_step_max))\n",
    "                new_ratio = float(self.volume_ratio) * (1.0 + step)\n",
    "            else:\n",
    "                new_ratio = float(self.volume_ratio)\n",
    "\n",
    "            self.volume_ratio = self._safe_clip_ratio(new_ratio, self.vol_frac_min, self.vol_frac_max)\n",
    "            self.density_GINN_model.volume_ratio = float(self.volume_ratio)\n",
    "            target_volume = float(self.volume_ratio) * float(JEB.domain_volume)\n",
    "\n",
    "\n",
    "            old_densities_list, sensitivities_list, coords_list = [], [], []\n",
    "\n",
    "            topo_funcs = topology_optimization(\n",
    "                self.u_model,\n",
    "                self.v_model,\n",
    "                self.w_model,\n",
    "                self.density_GINN_model,\n",
    "                n_opt_samples,\n",
    "                self.training_hparams,\n",
    "                self.enforce_density\n",
    "            )\n",
    "\n",
    "            for _ in tqdm(range(self.n_opt_batches), desc=\"Computing Target Densities\"):\n",
    "                coords = next(GINN_point_sampler)\n",
    "                densities, sensitivities = topo_funcs.compute_sensitivities(coords)\n",
    "\n",
    "                densities, sensitivities = self.enforce_density.apply(\n",
    "                    coords, densities, sensitivities, n_opt_samples, JEB.domain\n",
    "                )\n",
    "\n",
    "                filtered_sensitivities = topo_funcs.apply_sensitivity_filter(\n",
    "                    coords, densities, sensitivities,\n",
    "                    n_samples=n_opt_samples, domain=JEB.domain, radius=self.filter_radius\n",
    "                )\n",
    "\n",
    "                old_densities_list.append(densities)\n",
    "                sensitivities_list.append(filtered_sensitivities)\n",
    "                coords_list.append(coords)\n",
    "\n",
    "            target_density_list = topo_funcs.compute_target_densities(\n",
    "                old_densities_list, sensitivities_list,\n",
    "                sample_volume=JEB.domain_volume,\n",
    "                target_volume=target_volume,\n",
    "                max_move=0.2,\n",
    "                damping_parameter=0.5\n",
    "            )\n",
    "\n",
    "            for coords, target_density in tqdm(\n",
    "                list(zip(coords_list, target_density_list)),\n",
    "                desc=\"Optimizing density field\",\n",
    "                total=len(coords_list)\n",
    "            ):\n",
    "                self.topology_optimization_step(density_GINN_optimizer, coords, target_density)\n",
    "\n",
    "            # ---- Update PINN ----\n",
    "            for _ in tqdm(range(self.n_sim_iterations), desc=\"Updating PINN\"):\n",
    "                coords = next(PINN_point_sampler)\n",
    "                self.PINN_update_step(coords, PINN_optimizer, n_sim_samples)\n",
    "\n",
    "            # ---- Stress & volume on binary geometry ----\n",
    "            sigma_metric, sigma_max, current_volume = self._measure_stress_volume_3d()\n",
    "\n",
    "            # ---- EMA to fight oscillations ----\n",
    "            if self.sigma_ema is None:\n",
    "                self.sigma_ema = sigma_metric\n",
    "            else:\n",
    "                a = self.sigma_ema_alpha\n",
    "                self.sigma_ema = (1.0 - a) * self.sigma_ema + a * sigma_metric\n",
    "\n",
    "            # ---- Compliance on current SIMP design ----\n",
    "            comp_now = self._estimate_compliance_internal_energy_3d(n_opt_samples)\n",
    "\n",
    "            self.hist_iters.append(it)\n",
    "            self.hist_sigma_metric.append(sigma_metric)\n",
    "            self.hist_sigma_max.append(sigma_max)\n",
    "            self.hist_volume.append(current_volume)\n",
    "            self.hist_compliance.append(comp_now)\n",
    "\n",
    "            self._log_optimization_metrics_csv(it, sigma_metric, sigma_max, current_volume, comp_now)\n",
    "\n",
    "\n",
    "            if (it % self.save_interval) == 0:\n",
    "                self._save_training_curves(it)\n",
    "\n",
    "            print(\n",
    "                f\"[iter {it}] C={comp_now:.4g},  V={current_volume:.4g},  \"\n",
    "                f\"σ_metric={sigma_metric:.4g} (σ_allow={self.sigma_allow:.4g})  \"\n",
    "                f\"| vol_ratio→{self.volume_ratio:.4f}  \"\n",
    "                f\"(target={target_volume/float(JEB.domain_volume):.4f}·V_domain)  \"\n",
    "                f\"| σ_max={sigma_max:.4g}\"\n",
    "            )\n",
    "\n",
    "            if (it % self.save_interval) == 0:\n",
    "                self._maybe_log_eval_metrics(phase=\"TOPO\", it=it, model_kind=\"density\")\n",
    "                print('Saving geometry & models to', self.save_path)\n",
    "\n",
    "                save_density_outputs_3d(\n",
    "                    self.density_GINN_model, JEB.domain, n_opt_samples,\n",
    "                    self.enforce_density, self.save_path, '',\n",
    "                    f'-{it:06d}', iso_level=self.plot_threshold\n",
    "                )\n",
    "\n",
    "                save_density_outputs_3d_unconstrained(\n",
    "                    self.density_GINN_model, JEB.domain, n_opt_samples,\n",
    "                    self.save_path, '', f'-{it:06d}', iso_level=self.plot_threshold\n",
    "                )\n",
    "\n",
    "                pts_it, u_it, v_it, w_it, vm_it = predict_uvw_sigma_points_3d(\n",
    "                    self.u_model, self.v_model, self.w_model, self.density_GINN_model,\n",
    "                    rho_threshold_plot=self.plot_threshold,\n",
    "                    n_eval_points=self.n_eval_points_plot,\n",
    "                    max_batch=self.max_batch_plot,\n",
    "                    device=self.device,\n",
    "                    test_case=self.test_case\n",
    "                )\n",
    "                png_it = os.path.join(self.save_path, f\"uvwvm-{it:06d}.png\")\n",
    "                save_uvw_sigma_to_file_3d(pts_it, u_it, v_it, w_it, vm_it, png_it, title=f\"Iteration {it}\")\n",
    "\n",
    "                torch.save(self.density_GINN_model.state_dict(), os.path.join(self.save_path, f\"density_GINN-{it:06d}.pth\"))\n",
    "                torch.save(self.u_model.state_dict(), os.path.join(self.save_path, f\"u_model-{it:06d}.pth\"))\n",
    "                torch.save(self.v_model.state_dict(), os.path.join(self.save_path, f\"v_model-{it:06d}.pth\"))\n",
    "                torch.save(self.w_model.state_dict(), os.path.join(self.save_path, f\"w_model-{it:06d}.pth\"))\n",
    "\n",
    "                self._save_topology_density_curves(it)\n",
    "                self._log_optimization_losses_csv(it, comp_now, sigma_metric, sigma_max, current_volume)\n",
    "\n",
    "        # ---- Final snapshot ----\n",
    "        save_density_outputs_3d(\n",
    "            self.density_GINN_model, JEB.domain, n_opt_samples,\n",
    "            self.enforce_density, self.save_path, '',\n",
    "            '-final', iso_level=self.plot_threshold\n",
    "        )\n",
    "\n",
    "        if len(self.hist_iters) > 0:\n",
    "            self._save_training_curves(self.hist_iters[-1])\n",
    "\n",
    "        torch.save(self.density_GINN_model.state_dict(), os.path.join(self.save_path, \"density_GINN-final.pth\"))\n",
    "        torch.save(self.u_model.state_dict(), os.path.join(self.save_path, \"u_model-final.pth\"))\n",
    "        torch.save(self.v_model.state_dict(), os.path.join(self.save_path, \"v_model-final.pth\"))\n",
    "        torch.save(self.w_model.state_dict(), os.path.join(self.save_path, \"w_model-final.pth\"))\n",
    "\n",
    "        print(\"Done. Results in:\", self.save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d588c",
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1770669020156,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "0f1d588c"
   },
   "outputs": [],
   "source": [
    "\n",
    "hparams_model = {\n",
    "    'Model_type'         : 'SIREN',\n",
    "    'num_hidden_layers'  : 3,\n",
    "    'num_hidden_neurons' : 280,\n",
    "\n",
    "    'SIREN_hparams': {\n",
    "        'Model_type'    : 'SIREN',\n",
    "        'layers'        : [180, 180, 180, 180],\n",
    "        'dimensionality': 3,\n",
    "        'w0_initial'    : 60,\n",
    "        'w0'            : 1,\n",
    "        'skip_connection': True,\n",
    "    },\n",
    "    'SIREN_SDF_hparams': {\n",
    "        'Model_type'    : 'SIREN',\n",
    "        'layers'        : [180, 180, 180, 180],\n",
    "        'dimensionality': 3,\n",
    "        'w0_initial'    : 15,\n",
    "        'w0'            : 2,\n",
    "        'skip_connection': True,\n",
    "    },\n",
    "    'WIRE_hparams':\n",
    "                    {   'Model_type' : 'WIRE',\n",
    "                        'layers'     : [180,180,180,180],\n",
    "                        'dimensionality': 3,\n",
    "                        'w0_initial' : 15,\n",
    "                        'w0'         : 2,\n",
    "                        'sigma0'     : 1,\n",
    "                        'sigma0_initial' : 1,\n",
    "                        'layer_type': 'real_gabor',\n",
    "                        'trainable' :  False,\n",
    "                        'skip_connection' : True,\n",
    "                    },\n",
    "    'MLP_hparams': {\n",
    "        'Model_type'    : 'MLP',\n",
    "        'layers'        : [180, 180, 180, 180],\n",
    "        'dimensionality': 3,\n",
    "        'activation_function': 'relu',\n",
    "        'use_bias'      : True,\n",
    "        'use_batch_norm': False,\n",
    "        'use_dropout'   : False,\n",
    "        'dropout_rate'  : 0.1,\n",
    "        'skip_connection': True,\n",
    "    },\n",
    "}\n",
    "\n",
    "hparams_feature_expansion = {\n",
    "    'Feature Type'    : 'None',\n",
    "    'Num Frequencies' : 3,\n",
    "    'Max Frequency'   : 100,\n",
    "}\n",
    "\n",
    "\n",
    "density_constraint_hparams = {\n",
    "    'enabled'            : True,\n",
    "    'priority'           : \"keep_over_prohibit\",\n",
    "}\n",
    "\n",
    "\n",
    "topo_hparams = {\n",
    "    'save_path'     : \"./JEB_new_density\",\n",
    "    'volume_ratio'  : None,\n",
    "    'lr_PINN'       : 3e-4,\n",
    "    'lr_GINN'       : 3e-4,\n",
    "    'save_interval' : 5,\n",
    "    'filter_radius' : 2.0,\n",
    "    'n_opt_iterations'              :  100,\n",
    "    'n_sim_iterations'              :  1000,\n",
    "    'n_pre_training_iterations_PINN': 2500,\n",
    "    'n_pre_training_iterations_density_GINN': 2500,\n",
    "    'n_pre_training_iterations_GINN': 300,\n",
    "    'n_opt_batches' : 50,\n",
    "    'seed'          : 43,\n",
    "    'rho_treshold'  : 0.25,\n",
    "    'stress_metric' : \"percentile\",\n",
    "    'sigma_allow'   :  400.0,\n",
    "    'stress_tol'    :  0.02,\n",
    "    'stress_percentile':  0.9995,\n",
    "    'ks_rho'        :     80.0,\n",
    "    'ks_size_correction': False,\n",
    "    'vol_frac_min'  : 0.02,\n",
    "    'vol_frac_max'  : 0.98,\n",
    "    'vol_step_min'  : 0.005,\n",
    "    'vol_step_max'  : 0.05,\n",
    "    'alpha_decrease': 0.50,\n",
    "    'beta_increase' : 0.25,\n",
    "    'n_eval_points_plot': 400_000,\n",
    "    'max_batch_plot'    : 120_000,\n",
    "}\n",
    "\n",
    "\n",
    "training_hparams = {\n",
    "    'total_sample_points': 80000,\n",
    "    'batch_size': 20000,\n",
    "    'num_neumann_points': 10000,\n",
    "    'dirichlet_pts': 5000,\n",
    "    'mollifier_alpha': 1,\n",
    "    'density_alpha': 2,\n",
    "    'density_exponent': 3,\n",
    "    \"grad_clipping_on\": True,\n",
    "    \"grad_clip\": 0.5,\n",
    "    \"auto_clip_on\": True,\n",
    "    \"auto_clip_percentile\": 0.9,\n",
    "    \"auto_clip_hist_len\": 100,\n",
    "    \"auto_clip_min_len\": 10,\n",
    "    \"refine_study\": False,\n",
    "}\n",
    "\n",
    "\n",
    "GINN_hparams ={\n",
    "    'eikonal_loss_weight' : 0.1,\n",
    "    'envelope_loss_weight': 10,\n",
    "    'connectivity_loss_weight': 50,\n",
    "    'holes_loss_weight': 50,\n",
    "    'interface_loss_weight': 1,\n",
    "    'prescribed_normals_loss_weight': 1,\n",
    "    'prescribed_thickness_loss_weight': 1,\n",
    "    'prohibited_region_loss_weight': 1,\n",
    "    'smoothness_loss_weight': 1e-2,\n",
    "    'num_points_envelope_loss': 12000,\n",
    "    'num_points_connectivity_loss': 60000,\n",
    "    'envelope_extension_factor': 0.2,\n",
    "    'num_points_interface_loss': 4096,\n",
    "    'num_points_normals_loss': 4096,\n",
    "    'clip_max_value': 1.0e+6,\n",
    "    'clip_min_value': 0,\n",
    "    'max_curv': 0,\n",
    "    'curv_start_epoch': 200,\n",
    "    'curv_ramp_epochs': 300,\n",
    "    'envelope_loss_weight_density':     0,\n",
    "    'connectivity_loss_weight_density': 0,\n",
    "}\n",
    "\n",
    "adaptive_weighting_hparams = {\n",
    "    'use_adaptive_weighting': True,\n",
    "    'alpha': 0.90,\n",
    "    'gamma': 1e-2,\n",
    "    'epsilon': 1e-8,\n",
    "    'objective_function': True,\n",
    "    'objective_losses': ['Smoothness Loss'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b8053",
   "metadata": {
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1770669020410,
     "user": {
      "displayName": "Ørjan Jaathun",
      "userId": "11935124029388210670"
     },
     "user_tz": -60
    },
    "id": "a77b8053"
   },
   "outputs": [],
   "source": [
    "density_GINN = density_GINN(hparams_model['SIREN_SDF_hparams'],\n",
    "                            hparams_feature_expansion,\n",
    "                            density_alpha=training_hparams['density_alpha'],\n",
    "                            volume_ratio=topo_hparams['volume_ratio'])\n",
    "\n",
    "SDF_GINN = SDF_GINN(hparams_model['SIREN_SDF_hparams'],\n",
    "                    hparams_feature_expansion)\n",
    "\n",
    "u_model = PINN(hparams_model['SIREN_hparams'],\n",
    "               hparams_feature_expansion,\n",
    "               training_hparams['mollifier_alpha'])\n",
    "\n",
    "v_model = PINN(hparams_model['SIREN_hparams'],\n",
    "               hparams_feature_expansion,\n",
    "               training_hparams['mollifier_alpha'])\n",
    "\n",
    "w_model = PINN(hparams_model['SIREN_hparams'],\n",
    "               hparams_feature_expansion,\n",
    "               training_hparams['mollifier_alpha'])\n",
    "\n",
    "\n",
    "Shape_Generator = model_training(u_model,\n",
    "                                 v_model,\n",
    "                                 w_model,\n",
    "                                 density_GINN,\n",
    "                                 SDF_GINN,\n",
    "                                 training_hparams,\n",
    "                                 topo_hparams,\n",
    "                                 density_constraint_hparams,\n",
    "                                 GINN_hparams,\n",
    "                                 adaptive_weighting_hparams,\n",
    "                                 JEB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40128044",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40128044",
    "outputId": "e6ee5b01-1674-4d92-8cc8-a0ba16bc6cb8"
   },
   "outputs": [],
   "source": [
    "Shape_Generator.generate_geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d754c87e",
   "metadata": {
    "id": "d754c87e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
